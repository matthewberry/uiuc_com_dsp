{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSP genomics.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthewberry/uiuc_com_dsp/blob/master/DSP_genomics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZlQjjAmJuSY",
        "colab_type": "text"
      },
      "source": [
        "Prep to document:\n",
        "* enable google apps\n",
        "* sign in to illinois google account\n",
        "* open this notebook\n",
        "* File -> Save a copy in Drive (and then File -> Locate in Drive to see where it's being saved; can return there to open it later if you need to)\n",
        "* open data dir\n",
        "* save to my drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RczciUOYuOzp",
        "colab_type": "text"
      },
      "source": [
        "## Installation\n",
        "\n",
        "The cell below installs software required to perform the analyses. Run the cell and wait for it to complete, which might take several minutes. You'll see lots of text output as the cell runs, but there's no need to read it unless the following cell fails.\n",
        "\n",
        "Once you've run this cell and confirmed that the next cell also succeeds, you shouldn't need to run this cell again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgrIxPJT-UiT",
        "colab_type": "code",
        "outputId": "bb7c1874-27ca-47b3-e398-e679496f295c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip3 install -I pyyaml==5.1.2 xmlrunner==1.7.7 redis==3.3.8\n",
        "!pip3 install git+https://github.com/KnowEnG/KnowEnG_Pipelines_Library.git@mjberry/update_dependencies\n",
        "!pip3 install git+https://github.com/KnowEnG/Data_Cleanup_Pipeline.git@mjberry/create_package\n",
        "!pip3 install git+https://github.com/KnowEnG/General_Clustering_Pipeline.git@mjberry/create_package\n",
        "!pip3 install git+https://github.com/KnowEnG/Samples_Clustering_Pipeline.git@mjberry/create_package\n",
        "!pip3 install git+https://github.com/KnowEnG/Feature_Prioritization_Pipeline.git@mjberry/create_package\n",
        "!pip3 install git+https://github.com/KnowEnG/Gene_Prioritization_Pipeline.git@mjberry/create_package\n",
        "!pip3 install git+https://github.com/KnowEnG/Geneset_Characterization_Pipeline.git@mjberry/create_package\n",
        "!pip3 install git+https://github.com/KnowEnG/Spreadsheets_Transformation.git@mjberry/create_package"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyyaml==5.1.2\n",
            "Collecting xmlrunner==1.7.7\n",
            "Collecting redis==3.3.8\n",
            "  Using cached https://files.pythonhosted.org/packages/bd/64/b1e90af9bf0c7f6ef55e46b81ab527b33b785824d65300bb65636534b530/redis-3.3.8-py2.py3-none-any.whl\n",
            "Installing collected packages: pyyaml, xmlrunner, redis\n",
            "Successfully installed pyyaml-5.1.2 redis-3.3.8 xmlrunner-1.7.7\n",
            "Collecting git+https://github.com/KnowEnG/KnowEnG_Pipelines_Library.git@mjberry/update_dependencies\n",
            "  Cloning https://github.com/KnowEnG/KnowEnG_Pipelines_Library.git (to revision mjberry/update_dependencies) to /tmp/pip-req-build-xhpth_kx\n",
            "  Running command git clone -q https://github.com/KnowEnG/KnowEnG_Pipelines_Library.git /tmp/pip-req-build-xhpth_kx\n",
            "  Running command git checkout -b mjberry/update_dependencies --track origin/mjberry/update_dependencies\n",
            "  Switched to a new branch 'mjberry/update_dependencies'\n",
            "  Branch 'mjberry/update_dependencies' set up to track remote branch 'mjberry/update_dependencies' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): knpackage==0.1.27 from git+https://github.com/KnowEnG/KnowEnG_Pipelines_Library.git@mjberry/update_dependencies in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: knpackage\n",
            "  Building wheel for knpackage (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for knpackage: filename=knpackage-0.1.27-cp36-none-any.whl size=14881 sha256=84810ce21339fc62f82f7a402e381dc48276f39329ef08887e7df28a5ce5ffa8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ck9a1xtq/wheels/70/c7/a1/ea0fd56a8738fc7ac1be0a105130930146120499fdc6606cb9\n",
            "Successfully built knpackage\n",
            "Collecting git+https://github.com/KnowEnG/Data_Cleanup_Pipeline.git@mjberry/create_package\n",
            "  Cloning https://github.com/KnowEnG/Data_Cleanup_Pipeline.git (to revision mjberry/create_package) to /tmp/pip-req-build-zynr5ko4\n",
            "  Running command git clone -q https://github.com/KnowEnG/Data_Cleanup_Pipeline.git /tmp/pip-req-build-zynr5ko4\n",
            "  Running command git checkout -b mjberry/create_package --track origin/mjberry/create_package\n",
            "  Switched to a new branch 'mjberry/create_package'\n",
            "  Branch 'mjberry/create_package' set up to track remote branch 'mjberry/create_package' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): kndatacleanup==0.1.24 from git+https://github.com/KnowEnG/Data_Cleanup_Pipeline.git@mjberry/create_package in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: kndatacleanup\n",
            "  Building wheel for kndatacleanup (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kndatacleanup: filename=kndatacleanup-0.1.24-cp36-none-any.whl size=21139 sha256=a4c55ce480ee5a0015fff2347f5181047750ba8a21991a9022609ddd5eff7f3b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t2u2_ks9/wheels/f3/08/5f/bef0910710b5daac6a29ae5ea34600c52c0457457cb9f4b010\n",
            "Successfully built kndatacleanup\n",
            "Collecting git+https://github.com/KnowEnG/General_Clustering_Pipeline.git@mjberry/create_package\n",
            "  Cloning https://github.com/KnowEnG/General_Clustering_Pipeline.git (to revision mjberry/create_package) to /tmp/pip-req-build-vvjqf80t\n",
            "  Running command git clone -q https://github.com/KnowEnG/General_Clustering_Pipeline.git /tmp/pip-req-build-vvjqf80t\n",
            "  Running command git checkout -b mjberry/create_package --track origin/mjberry/create_package\n",
            "  Switched to a new branch 'mjberry/create_package'\n",
            "  Branch 'mjberry/create_package' set up to track remote branch 'mjberry/create_package' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): kngeneralclustering==0.1.24 from git+https://github.com/KnowEnG/General_Clustering_Pipeline.git@mjberry/create_package in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: kngeneralclustering\n",
            "  Building wheel for kngeneralclustering (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kngeneralclustering: filename=kngeneralclustering-0.1.24-cp36-none-any.whl size=10199 sha256=8569c3217b335b87c93e8af0681e08c673fc801e513677b0641418352b4927a1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-n_olfuck/wheels/82/14/fd/bbb4f8b52ee93f81fb3a0fd0d84aa0e0d32284aa8e2b794e76\n",
            "Successfully built kngeneralclustering\n",
            "Collecting git+https://github.com/KnowEnG/Samples_Clustering_Pipeline.git@mjberry/create_package\n",
            "  Cloning https://github.com/KnowEnG/Samples_Clustering_Pipeline.git (to revision mjberry/create_package) to /tmp/pip-req-build-7l64nek3\n",
            "  Running command git clone -q https://github.com/KnowEnG/Samples_Clustering_Pipeline.git /tmp/pip-req-build-7l64nek3\n",
            "  Running command git checkout -b mjberry/create_package --track origin/mjberry/create_package\n",
            "  Switched to a new branch 'mjberry/create_package'\n",
            "  Branch 'mjberry/create_package' set up to track remote branch 'mjberry/create_package' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): knsamplesclustering==0.1.24 from git+https://github.com/KnowEnG/Samples_Clustering_Pipeline.git@mjberry/create_package in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: knsamplesclustering\n",
            "  Building wheel for knsamplesclustering (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for knsamplesclustering: filename=knsamplesclustering-0.1.24-cp36-none-any.whl size=10306 sha256=67ed73cf8e71b96fa3bc7e4800cf1f2e1aa1872c40044c863daef1ec6464dc8b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gkavvvwh/wheels/c4/9d/6e/142001d49f00deb23c6e1024de10a7941d8ed95c41f34e538b\n",
            "Successfully built knsamplesclustering\n",
            "Collecting git+https://github.com/KnowEnG/Feature_Prioritization_Pipeline.git@mjberry/create_package\n",
            "  Cloning https://github.com/KnowEnG/Feature_Prioritization_Pipeline.git (to revision mjberry/create_package) to /tmp/pip-req-build-nk9z3jgd\n",
            "  Running command git clone -q https://github.com/KnowEnG/Feature_Prioritization_Pipeline.git /tmp/pip-req-build-nk9z3jgd\n",
            "  Running command git checkout -b mjberry/create_package --track origin/mjberry/create_package\n",
            "  Switched to a new branch 'mjberry/create_package'\n",
            "  Branch 'mjberry/create_package' set up to track remote branch 'mjberry/create_package' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): knfeatureprioritization==0.1.24 from git+https://github.com/KnowEnG/Feature_Prioritization_Pipeline.git@mjberry/create_package in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: knfeatureprioritization\n",
            "  Building wheel for knfeatureprioritization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for knfeatureprioritization: filename=knfeatureprioritization-0.1.24-cp36-none-any.whl size=9532 sha256=efc4aedb9ae930f50f4d94d195656fbe7980f6c7ddf12147ca04604a75f07175\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wj4pfc4t/wheels/9e/d2/d4/f01da17cddd382a7feba9fc395c395726466f119441ad44c3a\n",
            "Successfully built knfeatureprioritization\n",
            "Collecting git+https://github.com/KnowEnG/Gene_Prioritization_Pipeline.git@mjberry/create_package\n",
            "  Cloning https://github.com/KnowEnG/Gene_Prioritization_Pipeline.git (to revision mjberry/create_package) to /tmp/pip-req-build-ym7kd6qk\n",
            "  Running command git clone -q https://github.com/KnowEnG/Gene_Prioritization_Pipeline.git /tmp/pip-req-build-ym7kd6qk\n",
            "  Running command git checkout -b mjberry/create_package --track origin/mjberry/create_package\n",
            "  Switched to a new branch 'mjberry/create_package'\n",
            "  Branch 'mjberry/create_package' set up to track remote branch 'mjberry/create_package' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): kngeneprioritization==0.1.24 from git+https://github.com/KnowEnG/Gene_Prioritization_Pipeline.git@mjberry/create_package in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: kngeneprioritization\n",
            "  Building wheel for kngeneprioritization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kngeneprioritization: filename=kngeneprioritization-0.1.24-cp36-none-any.whl size=8669 sha256=db7e167958d5f1698863280e419def5e164d44aa2d4dc8b56b4aa5f477ecc174\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xcujbuk2/wheels/43/81/4a/aa00410bb14cb46d36d646124b48aeee4214f6ec86fdcf553c\n",
            "Successfully built kngeneprioritization\n",
            "Collecting git+https://github.com/KnowEnG/Geneset_Characterization_Pipeline.git@mjberry/create_package\n",
            "  Cloning https://github.com/KnowEnG/Geneset_Characterization_Pipeline.git (to revision mjberry/create_package) to /tmp/pip-req-build-ibc5ypws\n",
            "  Running command git clone -q https://github.com/KnowEnG/Geneset_Characterization_Pipeline.git /tmp/pip-req-build-ibc5ypws\n",
            "  Running command git checkout -b mjberry/create_package --track origin/mjberry/create_package\n",
            "  Switched to a new branch 'mjberry/create_package'\n",
            "  Branch 'mjberry/create_package' set up to track remote branch 'mjberry/create_package' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): kngenesetcharacterization==0.1.24 from git+https://github.com/KnowEnG/Geneset_Characterization_Pipeline.git@mjberry/create_package in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: kngenesetcharacterization\n",
            "  Building wheel for kngenesetcharacterization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kngenesetcharacterization: filename=kngenesetcharacterization-0.1.24-cp36-none-any.whl size=9119 sha256=4fcd714ba7e58ecbd0fe21169bfa455aac0aeda889419a9b6fa5125e498e7f47\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-s8tx22yx/wheels/94/a3/3c/32ab0c5021ca5e3a783032f1066934c00bd22858721689a878\n",
            "Successfully built kngenesetcharacterization\n",
            "Collecting git+https://github.com/KnowEnG/Spreadsheets_Transformation.git@mjberry/create_package\n",
            "  Cloning https://github.com/KnowEnG/Spreadsheets_Transformation.git (to revision mjberry/create_package) to /tmp/pip-req-build-a3eg96dm\n",
            "  Running command git clone -q https://github.com/KnowEnG/Spreadsheets_Transformation.git /tmp/pip-req-build-a3eg96dm\n",
            "  Running command git checkout -b mjberry/create_package --track origin/mjberry/create_package\n",
            "  Switched to a new branch 'mjberry/create_package'\n",
            "  Branch 'mjberry/create_package' set up to track remote branch 'mjberry/create_package' from 'origin'.\n",
            "Building wheels for collected packages: knspreadsheetstransformation\n",
            "  Building wheel for knspreadsheetstransformation (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for knspreadsheetstransformation: filename=knspreadsheetstransformation-0.1.27-cp36-none-any.whl size=15301 sha256=daeb6221e981fe40f176d1e00ce4f24f37a98b96d0447cfb0340293aeb586d0c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2f8tsnyb/wheels/b1/f4/2f/2624ac2197f0da315de8c9fc4668ee50b86e717de75b3416c4\n",
            "Successfully built knspreadsheetstransformation\n",
            "Installing collected packages: knspreadsheetstransformation\n",
            "Successfully installed knspreadsheetstransformation-0.1.27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftgYqoTDuzOu",
        "colab_type": "text"
      },
      "source": [
        "## Environment Setup\n",
        "\n",
        "This cell sets up the environment for running the analyses. Run the cell and wait for it to complete. You won't see any text output this time.\n",
        "\n",
        "You won't need to run this cell again, and you probably won't need to call any of the methods it defines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ifxh2nzm173",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import os\n",
        "import shutil\n",
        "import urllib.request\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "from kndatacleanup import data_cleanup\n",
        "from knfeatureprioritization import feature_prioritization\n",
        "from kngeneprioritization import gene_prioritization\n",
        "from kngenesetcharacterization import geneset_characterization\n",
        "from knsamplesclustering import samples_clustering\n",
        "from kngeneralclustering import general_clustering\n",
        "\n",
        "NETWORK_DIR_PATH = '/network/'\n",
        "\n",
        "REDIS_PARAMS = {\n",
        "    'host': 'knowredis.knoweng.org',\n",
        "    'password': 'KnowEnG',\n",
        "    'port': 6379\n",
        "}\n",
        "\n",
        "NUM_CPUS = 2\n",
        "\n",
        "def fetch_network(edge_file_path):\n",
        "    \"\"\"TODO\"\"\"\n",
        "    if not os.path.isfile(edge_file_path):\n",
        "        url = \"https://s3.amazonaws.com/KnowNets/KN-20rep-1706/\" + \\\n",
        "            \"userKN-20rep-1706/\" + edge_file_path[len(NETWORK_DIR_PATH)-1:]\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            with open(edge_file_path, 'wb') as out_file:\n",
        "                shutil.copyfileobj(response, out_file)\n",
        "\n",
        "def fetch_network_metadata():\n",
        "    filenames = ['db_contents.txt', 'species_desc.txt', 'edge_type.txt']\n",
        "    for filename in filenames:\n",
        "        out_file_path = os.path.join(NETWORK_DIR_PATH, filename)\n",
        "        if not os.path.isfile(out_file_path):\n",
        "            url = \"https://s3.amazonaws.com/KnowNets/KN-20rep-1706/\" + \\\n",
        "                \"userKN-20rep-1706/\" + filename\n",
        "            with urllib.request.urlopen(url) as response:\n",
        "                with open(out_file_path, 'wb') as out_file:\n",
        "                    shutil.copyfileobj(response, out_file)\n",
        "\n",
        "def get_path_to_newest_file_having_prefix(search_dir_path, prefix):\n",
        "    \"\"\"TODO\"\"\"\n",
        "    matches = [os.path.join(search_dir_path, name) for name \\\n",
        "        in os.listdir(search_dir_path) if name.startswith(prefix)]\n",
        "    if matches:\n",
        "        return sorted(matches, key=lambda path: os.path.getctime(path), reverse=True)[0]\n",
        "    else:\n",
        "        raise Exception(\"No file found with prefix \" + prefix + \" in \" + \\\n",
        "            search_dir_path + \".\")\n",
        "\n",
        "def get_cleaned_file_path(original_file_path, results_dir_path):\n",
        "    \"\"\"TODO\"\"\"\n",
        "    original_name = os.path.basename(original_file_path)\n",
        "    original_name_root = os.path.splitext(original_name)[0]\n",
        "    return os.path.join(results_dir_path, original_name_root + \"_ETL.tsv\")\n",
        "\n",
        "def get_gene_map_file_path(original_file_path, results_dir_path):\n",
        "    \"\"\"TODO\"\"\"\n",
        "    original_name = os.path.basename(original_file_path)\n",
        "    original_name_root = os.path.splitext(original_name)[0]\n",
        "    return os.path.join(results_dir_path, original_name_root + \"_MAP.tsv\")\n",
        "\n",
        "os.makedirs(NETWORK_DIR_PATH, exist_ok=True)\n",
        "fetch_network_metadata()\n",
        "\n",
        "!rm -rf /content/sample_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4DCoKLVwBvT",
        "colab_type": "text"
      },
      "source": [
        "## Knowledge Network Utility Methods\n",
        "\n",
        "This cell defines several utility methods for working with the knowledge network. These methods are used in the example analyses and might be useful to you in your project. Run this cell and wait for it to complete. It won't produce any text output.\n",
        "\n",
        "You won't need to edit anything within this cell or run it more than once. The next cell shows how to use the knowledge network utility methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKn3Uxx6rLce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_network_species():\n",
        "    \"\"\"TODO\"\"\"\n",
        "    return_val = []\n",
        "    species_file_path = os.path.join(NETWORK_DIR_PATH, 'species_desc.txt')\n",
        "    with open(species_file_path) as csvfile:\n",
        "        for row in csv.reader(csvfile, delimiter='\\t'):\n",
        "            return_val.append({\n",
        "                'id': row[0],\n",
        "                'short_latin_name': row[1],\n",
        "                'latin_name': row[2],\n",
        "                'familiar_name': row[3],\n",
        "                'group_name': row[5]\n",
        "            })\n",
        "    return return_val\n",
        "\n",
        "def display_network_species():\n",
        "    \"\"\"TODO\"\"\"\n",
        "    html_string = \"<table><tr><th>Familiar Name (Latin Name)</th><th>Species Id</th></tr>\"\n",
        "    for species in get_network_species():\n",
        "        html_string += \"<tr><td>\" + species['familiar_name'] + \" (\" + \\\n",
        "            species['latin_name'] + \")</td><td>\" + species['id'] + \"</td></tr>\"\n",
        "    html_string += \"</table>\"\n",
        "    return HTML(html_string)\n",
        "\n",
        "def get_interaction_networks(species_id):\n",
        "    \"\"\"TODO\"\"\"\n",
        "    species_id = str(species_id) # user-friendliness\n",
        "    return_val = []\n",
        "    contents_file_path = os.path.join(NETWORK_DIR_PATH, 'db_contents.txt')\n",
        "    with open(contents_file_path) as csvfile:\n",
        "        for row in csv.DictReader(csvfile, delimiter='\\t'):\n",
        "            if row['n1_type'] == 'Gene' and row['taxon'] == species_id:\n",
        "                return_val.append({\n",
        "                    'name': row['et_name'],\n",
        "                    'edge_file_path': os.path.join(\\\n",
        "                        NETWORK_DIR_PATH, 'Gene', species_id, row['et_name'], \\\n",
        "                        species_id + '.' + row['et_name'] + '.edge')\n",
        "                })\n",
        "    return return_val\n",
        "\n",
        "def display_interaction_networks(species_id):\n",
        "    \"\"\"TODO\"\"\"\n",
        "    html_string = \"<table><tr><th>Interaction Network Name</th><th>Edge File Path</th></tr>\"\n",
        "    for network in get_interaction_networks(species_id):\n",
        "        html_string += \"<tr><td>\" + network['name'] + \"</td><td>\" + \\\n",
        "            network['edge_file_path'] + \"</td></tr>\"\n",
        "    html_string += \"</table>\"\n",
        "    return HTML(html_string)\n",
        "\n",
        "def get_gene_property_networks(species_id):\n",
        "    \"\"\"TODO\"\"\"\n",
        "    species_id = str(species_id) # user-friendliness\n",
        "    return_val = []\n",
        "    contents_file_path = os.path.join(NETWORK_DIR_PATH, 'db_contents.txt')\n",
        "    with open(contents_file_path) as csvfile:\n",
        "        for row in csv.DictReader(csvfile, delimiter='\\t'):\n",
        "            if row['n1_type'] == 'Property' and row['taxon'] == species_id:\n",
        "                return_val.append({\n",
        "                    'name': row['et_name'],\n",
        "                    'edge_file_path': os.path.join(\\\n",
        "                        NETWORK_DIR_PATH, 'Property', species_id, row['et_name'], \\\n",
        "                        species_id + '.' + row['et_name'] + '.edge')\n",
        "                })\n",
        "    return return_val\n",
        "\n",
        "def display_gene_property_networks(species_id):\n",
        "    \"\"\"TODO\"\"\"\n",
        "    html_string = \"<table><tr><th>Interaction Network Name</th><th>Edge File Path</th></tr>\"\n",
        "    for network in get_gene_property_networks(species_id):\n",
        "        html_string += \"<tr><td>\" + network['name'] + \"</td><td>\" + \\\n",
        "            network['edge_file_path'] + \"</td></tr>\"\n",
        "    html_string += \"</table>\"\n",
        "    return HTML(html_string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVvYGbnRxE-9",
        "colab_type": "text"
      },
      "source": [
        "### Using the Knowledge Network Utility Methods\n",
        "\n",
        "The cells below show how `display_network_species`, `display_interaction_networks`, and `display_gene_property_networks` can be called to view information about the knowledge network. This information can be useful in configuring analyses, as you'll see later.\n",
        "\n",
        "These methods are based on three other methods, `get_network_species`, `get_interaction_networks`, and `get_gene_property_networks`. The \"get\" versions return the same information as the \"display\" versions, but the \"get\" versions return it in a format convenient for use in code instead of a format that's easy to read."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSMHjVi6tnNc",
        "colab_type": "code",
        "outputId": "c228954c-625b-493f-8545-0e22e7267398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "source": [
        "# display all species in the knowledge network\n",
        "display_network_species()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table><tr><th>Familiar Name (Latin Name)</th><th>Species Id</th></tr><tr><td>Human (Homo sapiens)</td><td>9606</td></tr><tr><td>Chimpanzee (Pan troglodytes)</td><td>9598</td></tr><tr><td>Cow (Bos taurus)</td><td>9913</td></tr><tr><td>Dog (Canis familiaris)</td><td>9615</td></tr><tr><td>Macaque (Macaca mulatta)</td><td>9544</td></tr><tr><td>Mouse (Mus musculus)</td><td>10090</td></tr><tr><td>Pig (Sus scrofa)</td><td>9823</td></tr><tr><td>Rat (Rattus norvegicus)</td><td>10116</td></tr><tr><td>Chicken (Gallus gallus)</td><td>9031</td></tr><tr><td>Clawed frog (Xenopus tropicalis)</td><td>8364</td></tr><tr><td>Stickleback (Gasterosteus aculeatus)</td><td>69293</td></tr><tr><td>Zebra finch (Taeniopygia guttata)</td><td>59729</td></tr><tr><td>Zebrafish (Danio rerio)</td><td>7955</td></tr><tr><td>Fruitfly (Drosophila melanogaster)</td><td>7227</td></tr><tr><td>Honey bee (Apis mellifera)</td><td>7460</td></tr><tr><td>Mosquito (Aedes aegypti)</td><td>7159</td></tr><tr><td>Roundworm (Caenorhabditis elegans)</td><td>6239</td></tr><tr><td>Thale cress (Arabidopsis thaliana)</td><td>3702</td></tr><tr><td>Water flea (Daphnia pulex)</td><td>6669</td></tr><tr><td>Yeast (Saccharomyces cerevisiae)</td><td>4932</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uep6yYfe83ly",
        "colab_type": "code",
        "outputId": "f72eb593-f22e-44cf-da07-efba80c2d4d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        }
      },
      "source": [
        "# display interaction networks for rat (species id 10116)\n",
        "display_interaction_networks('10116')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table><tr><th>Interaction Network Name</th><th>Edge File Path</th></tr><tr><td>blastp_homology</td><td>/network/Gene/10116/blastp_homology/10116.blastp_homology.edge</td></tr><tr><td>pathcom_catalysis_precedes</td><td>/network/Gene/10116/pathcom_catalysis_precedes/10116.pathcom_catalysis_precedes.edge</td></tr><tr><td>pathcom_controls_expression_of</td><td>/network/Gene/10116/pathcom_controls_expression_of/10116.pathcom_controls_expression_of.edge</td></tr><tr><td>pathcom_controls_phosphorylation_of</td><td>/network/Gene/10116/pathcom_controls_phosphorylation_of/10116.pathcom_controls_phosphorylation_of.edge</td></tr><tr><td>pathcom_controls_state_change_of</td><td>/network/Gene/10116/pathcom_controls_state_change_of/10116.pathcom_controls_state_change_of.edge</td></tr><tr><td>pathcom_in_complex_with</td><td>/network/Gene/10116/pathcom_in_complex_with/10116.pathcom_in_complex_with.edge</td></tr><tr><td>PPI_association</td><td>/network/Gene/10116/PPI_association/10116.PPI_association.edge</td></tr><tr><td>PPI_colocalization</td><td>/network/Gene/10116/PPI_colocalization/10116.PPI_colocalization.edge</td></tr><tr><td>PPI_direct_interaction</td><td>/network/Gene/10116/PPI_direct_interaction/10116.PPI_direct_interaction.edge</td></tr><tr><td>PPI_genetic_interaction</td><td>/network/Gene/10116/PPI_genetic_interaction/10116.PPI_genetic_interaction.edge</td></tr><tr><td>PPI_physical_association</td><td>/network/Gene/10116/PPI_physical_association/10116.PPI_physical_association.edge</td></tr><tr><td>reactome_PPI_direct_complex</td><td>/network/Gene/10116/reactome_PPI_direct_complex/10116.reactome_PPI_direct_complex.edge</td></tr><tr><td>reactome_PPI_indirect_complex</td><td>/network/Gene/10116/reactome_PPI_indirect_complex/10116.reactome_PPI_indirect_complex.edge</td></tr><tr><td>reactome_PPI_reaction</td><td>/network/Gene/10116/reactome_PPI_reaction/10116.reactome_PPI_reaction.edge</td></tr><tr><td>STRING_coexpression</td><td>/network/Gene/10116/STRING_coexpression/10116.STRING_coexpression.edge</td></tr><tr><td>STRING_database</td><td>/network/Gene/10116/STRING_database/10116.STRING_database.edge</td></tr><tr><td>STRING_experimental</td><td>/network/Gene/10116/STRING_experimental/10116.STRING_experimental.edge</td></tr><tr><td>STRING_fusion</td><td>/network/Gene/10116/STRING_fusion/10116.STRING_fusion.edge</td></tr><tr><td>STRING_neighborhood</td><td>/network/Gene/10116/STRING_neighborhood/10116.STRING_neighborhood.edge</td></tr><tr><td>STRING_textmining</td><td>/network/Gene/10116/STRING_textmining/10116.STRING_textmining.edge</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNl8XB-T84x5",
        "colab_type": "code",
        "outputId": "430dff08-aeda-4f3f-ec43-cade186d2d69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# display gene property networks for roundworm (species id 6239)\n",
        "display_gene_property_networks('6239')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table><tr><th>Interaction Network Name</th><th>Edge File Path</th></tr><tr><td>gene_ontology</td><td>/network/Property/6239/gene_ontology/6239.gene_ontology.edge</td></tr><tr><td>pathcom_pathway</td><td>/network/Property/6239/pathcom_pathway/6239.pathcom_pathway.edge</td></tr><tr><td>pfam_prot</td><td>/network/Property/6239/pfam_prot/6239.pfam_prot.edge</td></tr><tr><td>reactome_annotation</td><td>/network/Property/6239/reactome_annotation/6239.reactome_annotation.edge</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmTUV9Lp_rK0",
        "colab_type": "text"
      },
      "source": [
        "## Analytics Methods\n",
        "\n",
        "The cell below defines methods for running clustering, prioritization, and gene-set characterization. Run the cell and wait for it to complete. It won't produce any output.\n",
        "\n",
        "You won't need to run this cell more than once unless you later change it as part of your project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M6MGR3K_pd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def do_clustering(\\\n",
        "    omics_file_path, phenotype_file_path, results_dir_path, num_clusters, \\\n",
        "    species_id, interaction_network_edge_file_path, network_influence, \\\n",
        "    num_bootstraps, bootstrap_sample_fraction):\n",
        "    \"\"\"TODO\"\"\"\n",
        "    os.makedirs(results_dir_path, exist_ok=True)\n",
        "\n",
        "    if interaction_network_edge_file_path is None:\n",
        "        pipeline_type = 'general_clustering_pipeline'\n",
        "    else:\n",
        "        fetch_network(interaction_network_edge_file_path)\n",
        "        pipeline_type = 'samples_clustering_pipeline'\n",
        "\n",
        "    cleanup_parameters = {\n",
        "        'spreadsheet_name_full_path': omics_file_path,\n",
        "        'pipeline_type': pipeline_type,\n",
        "        'results_directory': results_dir_path\n",
        "    }\n",
        "    if phenotype_file_path is not None:\n",
        "        cleanup_parameters['phenotype_name_full_path'] = phenotype_file_path\n",
        "    if interaction_network_edge_file_path is not None:\n",
        "        cleanup_parameters.update({\n",
        "            'gg_network_name_full_path': interaction_network_edge_file_path,\n",
        "            'taxonid': species_id,\n",
        "            'source_hint': '',\n",
        "            'redis_credential': {\n",
        "                'host': REDIS_PARAMS['host'],\n",
        "                'port': REDIS_PARAMS['port'],\n",
        "                'password': REDIS_PARAMS['password']\n",
        "            }\n",
        "        })\n",
        "    data_cleanup.run_pipelines(cleanup_parameters, data_cleanup.SELECT[pipeline_type])\n",
        "\n",
        "    clustering_parameters = {\n",
        "        'spreadsheet_name_full_path': get_cleaned_file_path(omics_file_path, results_dir_path),\n",
        "        'results_directory': results_dir_path,\n",
        "        'processing_method': 'parallel',\n",
        "        'parallelism': NUM_CPUS,\n",
        "        'number_of_clusters': num_clusters,\n",
        "        'tmp_directory': './tmp'\n",
        "    }\n",
        "    if phenotype_file_path is not None:\n",
        "        clustering_parameters.update({\n",
        "            'phenotype_name_full_path': get_cleaned_file_path(pheno_file_path, results_dir_path),\n",
        "            'threshold': 15\n",
        "        })\n",
        "\n",
        "    method_prefix = ''\n",
        "    if num_bootstraps > 0:\n",
        "        clustering_parameters.update({\n",
        "            'number_of_bootstraps': num_bootstraps,\n",
        "            'rows_sampling_fraction': 1.0,\n",
        "            'cols_sampling_fraction': bootstrap_sample_fraction\n",
        "        })\n",
        "        method_prefix = 'cc_'\n",
        "\n",
        "    if interaction_network_edge_file_path is not None:\n",
        "        clustering_parameters.update({\n",
        "            'gg_network_name_full_path': interaction_network_edge_file_path,\n",
        "            'rwr_max_iterations': 100,\n",
        "            'rwr_convergence_tolerence': 1.0e-4,\n",
        "            'rwr_restart_probability': network_influence,\n",
        "            'top_number_of_genes': 100,\n",
        "            'nmf_conv_check_freq': 50,\n",
        "            'nmf_max_invariance': 200,\n",
        "            'nmf_max_iterations': 10000,\n",
        "            'nmf_penalty_parameter': 1400,\n",
        "            'method': method_prefix + 'net_nmf'\n",
        "        })\n",
        "        samples_clustering.SELECT[clustering_parameters['method']](clustering_parameters)\n",
        "    else:\n",
        "        clustering_parameters.update({\n",
        "            'top_number_of_rows': 100,\n",
        "            'affinity_metric': 'euclidean',\n",
        "            'linkage_criterion': 'ward',\n",
        "            'method': method_prefix + 'hclust'\n",
        "        })\n",
        "        general_clustering.SELECT[clustering_parameters['method']](clustering_parameters)\n",
        "\n",
        "def do_prioritization(\\\n",
        "    omics_file_path, phenotype_file_path, results_dir_path, \\\n",
        "    correlation_measure, missing_value_strategy, num_exported_features, \\\n",
        "    num_response_correlated_features, species_id, \\\n",
        "    interaction_network_edge_file_path, network_influence):\n",
        "    \"\"\"TODO\"\"\"\n",
        "    os.makedirs(results_dir_path, exist_ok=True)\n",
        "\n",
        "    if interaction_network_edge_file_path is None:\n",
        "        pipeline_type = 'feature_prioritization_pipeline'\n",
        "    else:\n",
        "        fetch_network(interaction_network_edge_file_path)\n",
        "        pipeline_type = 'gene_prioritization_pipeline'\n",
        "\n",
        "    cleanup_parameters = {\n",
        "        'spreadsheet_name_full_path': omics_file_path,\n",
        "        'phenotype_name_full_path': phenotype_file_path,\n",
        "        'pipeline_type': pipeline_type,\n",
        "        'correlation_measure': correlation_measure, # t_test, pearson, edgeR\n",
        "        'impute': missing_value_strategy, # average, remove, reject\n",
        "        'results_directory': results_dir_path\n",
        "    }\n",
        "    if interaction_network_edge_file_path is not None:\n",
        "        cleanup_parameters.update({\n",
        "            'taxonid': species_id,\n",
        "            'source_hint': '',\n",
        "            'redis_credential': {\n",
        "                    'host': REDIS_PARAMS['host'],\n",
        "                    'port': REDIS_PARAMS['port'],\n",
        "                    'password': REDIS_PARAMS['password']\n",
        "            }\n",
        "        })\n",
        "    data_cleanup.run_pipelines(cleanup_parameters, data_cleanup.SELECT[pipeline_type])\n",
        "\n",
        "    prioritization_parameters = {\n",
        "        'correlation_measure': correlation_method,\n",
        "        'spreadsheet_name_full_path': get_cleaned_file_path(omics_file_path, results_dir_path),\n",
        "        'phenotype_name_full_path': get_cleaned_file_path(pheno_file_path, results_dir_path),\n",
        "        'results_directory': results_dir_path,\n",
        "        'top_gamma_of_sort': num_exported_features,\n",
        "        'max_cpu': NUM_CPUS\n",
        "    }\n",
        "    if gg_network_name_full_path is not None:\n",
        "        prioritization_parameters.update({\n",
        "            'gg_network_name_full_path': interaction_network_edge_file_path,\n",
        "            'rwr_max_iterations': 100,\n",
        "            'rwr_convergence_tolerence': 1.0e-4,\n",
        "            'rwr_restart_probability': network_influence,\n",
        "            'top_beta_of_sort': num_response_correlated_features,\n",
        "            'method': 'net_correlation'\n",
        "        })\n",
        "        gene_prioritization.net_correlation(prioritization_parameters)\n",
        "    else:\n",
        "        prioritization_parameters.update({\n",
        "            'top_beta_of_sort': num_exported_features,\n",
        "            'method': 'correlation',\n",
        "        })\n",
        "        feature_prioritization.correlation(prioritization_parameters)\n",
        "\n",
        "def do_characterization(\\\n",
        "    gene_matrix_file_path, results_dir_path, species_id, \\\n",
        "    gene_property_edge_file_path, interaction_network_edge_file_path, \\\n",
        "    network_influence):\n",
        "    \"\"\"TODO\"\"\"\n",
        "    os.makedirs(results_dir_path, exist_ok=True)\n",
        "\n",
        "    fetch_network(gene_property_edge_file_path)\n",
        "\n",
        "    cleanup_parameters = {\n",
        "        'spreadsheet_name_full_path': gene_matrix_file_path,\n",
        "        'pipeline_type': 'geneset_characterization_pipeline',\n",
        "        'results_directory': results_dir_path,\n",
        "        'taxonid': species_id,\n",
        "        'source_hint': '',\n",
        "        'redis_credential': {\n",
        "            'host': REDIS_PARAMS['host'],\n",
        "            'port': REDIS_PARAMS['port'],\n",
        "            'password': REDIS_PARAMS['password']\n",
        "        }\n",
        "    }\n",
        "    data_cleanup.run_pipelines(cleanup_parameters, data_cleanup.SELECT[pipeline_type])\n",
        "\n",
        "    characterization_parameters = {\n",
        "        'spreadsheet_name_full_path': get_cleaned_file_path(gene_matrix_file_path, results_dir_path),\n",
        "        'gene_names_map': get_gene_map_path(gene_matrix_file_path, results_dir_path),\n",
        "        'results_directory': results_dir_path,\n",
        "        'pg_network_name_full_path': gene_property_edge_file_path,\n",
        "        'max_cpu': NUM_CPUS\n",
        "    }\n",
        "    if interaction_network_edge_file_path is None:\n",
        "        characterization_parameters.update({\n",
        "            'method': 'fisher'\n",
        "        })\n",
        "        geneset_characterization.fisher(characterization_parameters)\n",
        "    else:\n",
        "        fetch_network(interaction_network_edge_file_path)\n",
        "        characterization_parameters.update({\n",
        "            'method': 'DRaWR',\n",
        "            'rwr_max_iterations': 500,\n",
        "            'rwr_convergence_tolerence': 1.0e-4,\n",
        "            'rwr_restart_probability': network_influence,\n",
        "            'gg_network_name_full_path': interaction_network_edge_file_path\n",
        "        })\n",
        "        geneset_characterization.DRaWR(characterization_parameters)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRxFpjpTM0b8",
        "colab_type": "text"
      },
      "source": [
        "## Connect to Google Drive\n",
        "\n",
        "The cell below will allow this notebook to use your Google Drive for file storage. Subsequent cells will use this access to load the example files you copied earlier and to save results of the example analyses. You might also find this helpful in your own analyses.\n",
        "\n",
        "Run the cell and click on the link that appears in the output. On the linked page, select your illinois.edu account and grant the requested permissions. The page will then display a code. Copy the code and paste it in the box that appears in the output below. Then press Enter.\n",
        "\n",
        "You might need to re-run this cell if your notebook is idle for a long period of time. The next section will explain how to determine whether re-running the cell is necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTqz9ZNXvlG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "GDRIVE_MOUNT_PATH = '/content/gdrive'\n",
        "drive.mount(GDRIVE_MOUNT_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC9dFiPKnLmv",
        "colab_type": "text"
      },
      "source": [
        "## Setting File Locations\n",
        "\n",
        "In the cell below, we will tell the notebook where the example files can be found and where the results should be saved.\n",
        "\n",
        "To confirm the location, find the arrow symbol (>) near the top left corner of the portion of your screen that shows the notebook content. Click it to reveal a panel with three tabs labeled `Table of contents`, `Code snippets`, and `Files`. Click on the `Files` tab.\n",
        "\n",
        "In the `Files` tab, you should see one folder named `gdrive`. Click the arrow next to the `gdrive` folder to expand it, and continue navigating through the folders until you find the `example_analyses` folder copied previously. Right-click on `example_analyses` and select `Copy path`. Paste the value into the cell below, and compare it to the value assigned to `INPUT_DATA_DIR_PATH`. If the values are different, replace the pre-coded value with the one you pasted. Once you have done that, run the cell.\n",
        "\n",
        "If at any point you open the `Files` tab or click its `REFRESH` button and do not see `gdrive`, you might need to re-run the previous cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnBOrd8rMm2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DATA_DIR_PATH = '/content/gdrive/My Drive/College of Medicine Data Science Project/Genomics/example_analyses'\n",
        "OUTPUT_DATA_DIR_PATH = os.path.join(INPUT_DATA_DIR_PATH, 'results')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t-CbUY6sP2K",
        "colab_type": "text"
      },
      "source": [
        "## Clustering\n",
        "\n",
        "The following four cells will use standard clustering techniques to group samples according to different omics data. Run each cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub32Jwwksg31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clustering1_dir_path = os.path.join(OUTPUT_DATA_DIR_PATH, 'clustering1')\n",
        "do_clustering(\\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_clustering1_genecopynumber.tsv'), \\\n",
        "    None, clustering1_dir_path, 8, None, None, None, 0, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKX0UCvmskVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clustering2_dir_path = os.path.join(OUTPUT_DATA_DIR_PATH, 'clustering2')\n",
        "do_clustering(\\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_clustering2_exp_HiSeqV2.tsv'), \\\n",
        "    None, clustering2_dir_path, 13, None, None, None, 0, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV7S9H7FsngW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clustering3_dir_path = os.path.join(OUTPUT_DATA_DIR_PATH, 'clustering3')\n",
        "do_clustering(\\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_clustering3_hMethyl.tsv'), \\\n",
        "    None, clustering3_dir_path, 19, None, None, None, 0, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFJcuLclspo5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clustering4_dir_path = os.path.join(OUTPUT_DATA_DIR_PATH, 'clustering4')\n",
        "do_clustering(\\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_clustering4_RPPA_RBN.tsv'), \\\n",
        "    None, clustering4_dir_path, 8, None, None, None, 0, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWMbtPJZssUT",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mnPXgrTss9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clustering5_dir_path = os.path.join(OUTPUT_DATA_DIR_PATH, 'clustering5')\n",
        "do_clustering(\\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_clustering5_mutation.tsv'), \\\n",
        "    None, clustering5_dir_path, 14, '9606', \\\n",
        "    '/hostmount/network/Gene/9606/hn_IntNet/9606.hn_IntNet.edge', 0.5, 0, None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}