{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSP genomics.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthewberry/uiuc_com_dsp/blob/master/DSP_genomics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZlQjjAmJuSY",
        "colab_type": "text"
      },
      "source": [
        "## Using This Notebook\n",
        "\n",
        "This notebook is an interactive environment that combines explanatory text with executable code. It provides computational tools useful in genomics, and you will familiarize yourself with them by stepping through a series of analyses that examine related data sets from multiple angles. This suite of tools and example can then serve as a starting point for a project of your own design.\n",
        "\n",
        "If you are new to notebooks, you might find this introduction helpful: [Overview of Colaboratory Features](https://colab.research.google.com/notebooks/basic_features_overview.ipynb) You might also want to refer to the [Python 3 documentation](https://docs.python.org/3/).\n",
        "\n",
        "**Important Note**: After a period of inactivity (Google does not specify exactly how long), Google will disconnect your notebook from the virtual machine that had been running it. When you return, Google will connect to a new virtual machine. Any data files you saved to your Google Drive will remain, but any variables or methods defined in your previous virtual machine will have to be reloaded. (You will know when this happens, because cells that previously ran without error will suddenly stop working, and the notebook will lose its connection to your Google Drive.) To reload the variable and method definitions, and to restore the connection to your Google Drive, you can simply re-run the cells that perform those tasks. This notebook will explain which cells might need to be re-run.\n",
        "\n",
        "Prep to document:\n",
        "* enable google apps\n",
        "* sign in to illinois google account\n",
        "* open this notebook\n",
        "* File -> Save a copy in Drive (and then File -> Locate in Drive to see where it's being saved; can return there to open it later if you need to)\n",
        "* open data dir\n",
        "* save to my drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RczciUOYuOzp",
        "colab_type": "text"
      },
      "source": [
        "## Installation\n",
        "\n",
        "The cell below installs software required to perform the analyses. Run the cell and wait for it to complete, which might take several minutes. You'll see lots of text output as the cell runs, but there's no need to read it unless the following cell fails.\n",
        "\n",
        "You **will** need to re-run this cell whenever your notebook connects to a new virtual machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgrIxPJT-UiT",
        "colab_type": "code",
        "outputId": "0d314947-415d-4478-c8e5-4285aa2b94b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip3 install -I pyyaml==5.1.2\n",
        "!pip3 install xmlrunner==1.7.7 redis==3.3.8 lifelines==0.22.8\n",
        "!pip3 install git+https://github.com/KnowEnG/KnowEnG_Pipelines_Library.git@mjberry/update_dependencies\n",
        "!pip3 install git+https://github.com/KnowEnG/Data_Cleanup_Pipeline.git@mjberry/create_package\n",
        "!pip3 install git+https://github.com/KnowEnG/General_Clustering_Pipeline.git@mjberry/create_package\n",
        "!pip3 install git+https://github.com/KnowEnG/Samples_Clustering_Pipeline.git@mjberry/create_package\n",
        "!pip3 install git+https://github.com/KnowEnG/Feature_Prioritization_Pipeline.git@mjberry/create_package\n",
        "!pip3 install git+https://github.com/KnowEnG/Gene_Prioritization_Pipeline.git@mjberry/create_package\n",
        "!pip3 install git+https://github.com/KnowEnG/Geneset_Characterization_Pipeline.git@mjberry/create_package\n",
        "!pip3 install git+https://github.com/KnowEnG/Spreadsheets_Transformation.git@mjberry/create_package"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyyaml==5.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\n",
            "\r\u001b[K     |█▎                              | 10kB 14.4MB/s eta 0:00:01\r\u001b[K     |██▌                             | 20kB 6.9MB/s eta 0:00:01\r\u001b[K     |███▊                            | 30kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 40kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 51kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 61kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 71kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 81kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 92kB 12.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 102kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 112kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 122kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 133kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 143kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 153kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 163kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 174kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 184kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 194kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 204kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 215kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 225kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 235kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 245kB 9.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 256kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 266kB 9.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1.2-cp36-cp36m-linux_x86_64.whl size=44104 sha256=268cfdf62c73f6ca0df4918258f5d95e02d7739ec1ae5ea9c031c7e44e3ed0ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "Successfully installed pyyaml-5.1.2\n",
            "Collecting xmlrunner==1.7.7\n",
            "  Downloading https://files.pythonhosted.org/packages/57/c0/a19e29bc6038a56bb690549573af6ea11a9d2a5c07aff2e27ed308c2cab9/xmlrunner-1.7.7.tar.gz\n",
            "Collecting redis==3.3.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/64/b1e90af9bf0c7f6ef55e46b81ab527b33b785824d65300bb65636534b530/redis-3.3.8-py2.py3-none-any.whl (66kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.7MB/s \n",
            "\u001b[?25hCollecting lifelines==0.22.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/96/74e1f74cc00474b969e137ab65246189b1e5841c6ab2eed98c65027bcfcb/lifelines-0.22.8-py2.py3-none-any.whl (338kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 16.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from lifelines==0.22.8) (1.3.1)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.6/dist-packages (from lifelines==0.22.8) (3.0.3)\n",
            "Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.6/dist-packages (from lifelines==0.22.8) (1.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from lifelines==0.22.8) (1.16.5)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from lifelines==0.22.8) (0.24.2)\n",
            "Collecting autograd-gamma>=0.3 (from lifelines==0.22.8)\n",
            "  Downloading https://files.pythonhosted.org/packages/3e/87/788c4bf90cc5c534cb3b7fdb5b719175e33e2658decce75e35e2ce69766f/autograd_gamma-0.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->lifelines==0.22.8) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->lifelines==0.22.8) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->lifelines==0.22.8) (2.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->lifelines==0.22.8) (2.5.3)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from autograd>=1.3->lifelines==0.22.8) (0.16.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->lifelines==0.22.8) (2018.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.0->lifelines==0.22.8) (41.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=3.0->lifelines==0.22.8) (1.12.0)\n",
            "Building wheels for collected packages: xmlrunner\n",
            "  Building wheel for xmlrunner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for xmlrunner: filename=xmlrunner-1.7.7-cp36-none-any.whl size=6235 sha256=8bfb72bc566cbf9e9e7e6d039c7289b04cdfb2b6813f5566bdb45d31cbf083a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/0e/05/28e4ff5b683c7a319756b412c7f4dc508a7ffa654e12c54ef5\n",
            "Successfully built xmlrunner\n",
            "Installing collected packages: xmlrunner, redis, autograd-gamma, lifelines\n",
            "Successfully installed autograd-gamma-0.4.1 lifelines-0.22.8 redis-3.3.8 xmlrunner-1.7.7\n",
            "Collecting git+https://github.com/KnowEnG/KnowEnG_Pipelines_Library.git@mjberry/update_dependencies\n",
            "  Cloning https://github.com/KnowEnG/KnowEnG_Pipelines_Library.git (to revision mjberry/update_dependencies) to /tmp/pip-req-build-0xtp85i7\n",
            "  Running command git clone -q https://github.com/KnowEnG/KnowEnG_Pipelines_Library.git /tmp/pip-req-build-0xtp85i7\n",
            "  Running command git checkout -b mjberry/update_dependencies --track origin/mjberry/update_dependencies\n",
            "  Switched to a new branch 'mjberry/update_dependencies'\n",
            "  Branch 'mjberry/update_dependencies' set up to track remote branch 'mjberry/update_dependencies' from 'origin'.\n",
            "Building wheels for collected packages: knpackage\n",
            "  Building wheel for knpackage (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for knpackage: filename=knpackage-0.1.27-cp36-none-any.whl size=14881 sha256=51346da690fc616bf10d151e989e8a5a0d16be158a0ee96d2940eadc13a32f77\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-netad9sg/wheels/70/c7/a1/ea0fd56a8738fc7ac1be0a105130930146120499fdc6606cb9\n",
            "Successfully built knpackage\n",
            "Installing collected packages: knpackage\n",
            "Successfully installed knpackage-0.1.27\n",
            "Collecting git+https://github.com/KnowEnG/Data_Cleanup_Pipeline.git@mjberry/create_package\n",
            "  Cloning https://github.com/KnowEnG/Data_Cleanup_Pipeline.git (to revision mjberry/create_package) to /tmp/pip-req-build-cjmnen_h\n",
            "  Running command git clone -q https://github.com/KnowEnG/Data_Cleanup_Pipeline.git /tmp/pip-req-build-cjmnen_h\n",
            "  Running command git checkout -b mjberry/create_package --track origin/mjberry/create_package\n",
            "  Switched to a new branch 'mjberry/create_package'\n",
            "  Branch 'mjberry/create_package' set up to track remote branch 'mjberry/create_package' from 'origin'.\n",
            "Building wheels for collected packages: kndatacleanup\n",
            "  Building wheel for kndatacleanup (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kndatacleanup: filename=kndatacleanup-0.1.24-cp36-none-any.whl size=21139 sha256=af957fa46bbc41b1d3ceb96eba3f6329c393b9db0ff014d4ef63ba026490da2d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sb9j1z16/wheels/f3/08/5f/bef0910710b5daac6a29ae5ea34600c52c0457457cb9f4b010\n",
            "Successfully built kndatacleanup\n",
            "Installing collected packages: kndatacleanup\n",
            "Successfully installed kndatacleanup-0.1.24\n",
            "Collecting git+https://github.com/KnowEnG/General_Clustering_Pipeline.git@mjberry/create_package\n",
            "  Cloning https://github.com/KnowEnG/General_Clustering_Pipeline.git (to revision mjberry/create_package) to /tmp/pip-req-build-ga3pcgcw\n",
            "  Running command git clone -q https://github.com/KnowEnG/General_Clustering_Pipeline.git /tmp/pip-req-build-ga3pcgcw\n",
            "  Running command git checkout -b mjberry/create_package --track origin/mjberry/create_package\n",
            "  Switched to a new branch 'mjberry/create_package'\n",
            "  Branch 'mjberry/create_package' set up to track remote branch 'mjberry/create_package' from 'origin'.\n",
            "Building wheels for collected packages: kngeneralclustering\n",
            "  Building wheel for kngeneralclustering (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kngeneralclustering: filename=kngeneralclustering-0.1.24-cp36-none-any.whl size=10199 sha256=c805754f312e6e86810dcb6c2ac0595c65629d4ad54b767ee5a2c4609c6dbe09\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gaj7zfb9/wheels/82/14/fd/bbb4f8b52ee93f81fb3a0fd0d84aa0e0d32284aa8e2b794e76\n",
            "Successfully built kngeneralclustering\n",
            "Installing collected packages: kngeneralclustering\n",
            "Successfully installed kngeneralclustering-0.1.24\n",
            "Collecting git+https://github.com/KnowEnG/Samples_Clustering_Pipeline.git@mjberry/create_package\n",
            "  Cloning https://github.com/KnowEnG/Samples_Clustering_Pipeline.git (to revision mjberry/create_package) to /tmp/pip-req-build-rdx0hwrq\n",
            "  Running command git clone -q https://github.com/KnowEnG/Samples_Clustering_Pipeline.git /tmp/pip-req-build-rdx0hwrq\n",
            "  Running command git checkout -b mjberry/create_package --track origin/mjberry/create_package\n",
            "  Switched to a new branch 'mjberry/create_package'\n",
            "  Branch 'mjberry/create_package' set up to track remote branch 'mjberry/create_package' from 'origin'.\n",
            "Building wheels for collected packages: knsamplesclustering\n",
            "  Building wheel for knsamplesclustering (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for knsamplesclustering: filename=knsamplesclustering-0.1.24-cp36-none-any.whl size=10306 sha256=7c04f20c5301a36e69e5e172988d9eec517276d3fd32d45d65ed4f1b0453384d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-yv3zs60s/wheels/c4/9d/6e/142001d49f00deb23c6e1024de10a7941d8ed95c41f34e538b\n",
            "Successfully built knsamplesclustering\n",
            "Installing collected packages: knsamplesclustering\n",
            "Successfully installed knsamplesclustering-0.1.24\n",
            "Collecting git+https://github.com/KnowEnG/Feature_Prioritization_Pipeline.git@mjberry/create_package\n",
            "  Cloning https://github.com/KnowEnG/Feature_Prioritization_Pipeline.git (to revision mjberry/create_package) to /tmp/pip-req-build-05c9175r\n",
            "  Running command git clone -q https://github.com/KnowEnG/Feature_Prioritization_Pipeline.git /tmp/pip-req-build-05c9175r\n",
            "  Running command git checkout -b mjberry/create_package --track origin/mjberry/create_package\n",
            "  Switched to a new branch 'mjberry/create_package'\n",
            "  Branch 'mjberry/create_package' set up to track remote branch 'mjberry/create_package' from 'origin'.\n",
            "Building wheels for collected packages: knfeatureprioritization\n",
            "  Building wheel for knfeatureprioritization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for knfeatureprioritization: filename=knfeatureprioritization-0.1.24-cp36-none-any.whl size=9532 sha256=02b8f815c0d223bf08a9395345febddca7ebd4a60f64f18288b948592b2aa0a0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fpo_1k5r/wheels/9e/d2/d4/f01da17cddd382a7feba9fc395c395726466f119441ad44c3a\n",
            "Successfully built knfeatureprioritization\n",
            "Installing collected packages: knfeatureprioritization\n",
            "Successfully installed knfeatureprioritization-0.1.24\n",
            "Collecting git+https://github.com/KnowEnG/Gene_Prioritization_Pipeline.git@mjberry/create_package\n",
            "  Cloning https://github.com/KnowEnG/Gene_Prioritization_Pipeline.git (to revision mjberry/create_package) to /tmp/pip-req-build-dvjx6gew\n",
            "  Running command git clone -q https://github.com/KnowEnG/Gene_Prioritization_Pipeline.git /tmp/pip-req-build-dvjx6gew\n",
            "  Running command git checkout -b mjberry/create_package --track origin/mjberry/create_package\n",
            "  Switched to a new branch 'mjberry/create_package'\n",
            "  Branch 'mjberry/create_package' set up to track remote branch 'mjberry/create_package' from 'origin'.\n",
            "Building wheels for collected packages: kngeneprioritization\n",
            "  Building wheel for kngeneprioritization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kngeneprioritization: filename=kngeneprioritization-0.1.24-cp36-none-any.whl size=8669 sha256=d4bf64226bedba6f3ecdbd920f67382da4653cbc7507433e001768da7ffd59cb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0v_gbh2s/wheels/43/81/4a/aa00410bb14cb46d36d646124b48aeee4214f6ec86fdcf553c\n",
            "Successfully built kngeneprioritization\n",
            "Installing collected packages: kngeneprioritization\n",
            "Successfully installed kngeneprioritization-0.1.24\n",
            "Collecting git+https://github.com/KnowEnG/Geneset_Characterization_Pipeline.git@mjberry/create_package\n",
            "  Cloning https://github.com/KnowEnG/Geneset_Characterization_Pipeline.git (to revision mjberry/create_package) to /tmp/pip-req-build-yrtwnwpv\n",
            "  Running command git clone -q https://github.com/KnowEnG/Geneset_Characterization_Pipeline.git /tmp/pip-req-build-yrtwnwpv\n",
            "  Running command git checkout -b mjberry/create_package --track origin/mjberry/create_package\n",
            "  Switched to a new branch 'mjberry/create_package'\n",
            "  Branch 'mjberry/create_package' set up to track remote branch 'mjberry/create_package' from 'origin'.\n",
            "Building wheels for collected packages: kngenesetcharacterization\n",
            "  Building wheel for kngenesetcharacterization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kngenesetcharacterization: filename=kngenesetcharacterization-0.1.24-cp36-none-any.whl size=9119 sha256=5bcbaa3b244af727583e6fd45732bffa5aa019215618d90e74b522141ea5961d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xhhhun9q/wheels/94/a3/3c/32ab0c5021ca5e3a783032f1066934c00bd22858721689a878\n",
            "Successfully built kngenesetcharacterization\n",
            "Installing collected packages: kngenesetcharacterization\n",
            "Successfully installed kngenesetcharacterization-0.1.24\n",
            "Collecting git+https://github.com/KnowEnG/Spreadsheets_Transformation.git@mjberry/create_package\n",
            "  Cloning https://github.com/KnowEnG/Spreadsheets_Transformation.git (to revision mjberry/create_package) to /tmp/pip-req-build-q00wg5_k\n",
            "  Running command git clone -q https://github.com/KnowEnG/Spreadsheets_Transformation.git /tmp/pip-req-build-q00wg5_k\n",
            "  Running command git checkout -b mjberry/create_package --track origin/mjberry/create_package\n",
            "  Switched to a new branch 'mjberry/create_package'\n",
            "  Branch 'mjberry/create_package' set up to track remote branch 'mjberry/create_package' from 'origin'.\n",
            "Building wheels for collected packages: knspreadsheetstransformation\n",
            "  Building wheel for knspreadsheetstransformation (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for knspreadsheetstransformation: filename=knspreadsheetstransformation-0.1.27-cp36-none-any.whl size=15301 sha256=a3bfb989c16883115664b4eb32373428a667a148daf062741ad3c4264cb4e3db\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6bfzmp58/wheels/b1/f4/2f/2624ac2197f0da315de8c9fc4668ee50b86e717de75b3416c4\n",
            "Successfully built knspreadsheetstransformation\n",
            "Installing collected packages: knspreadsheetstransformation\n",
            "Successfully installed knspreadsheetstransformation-0.1.27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftgYqoTDuzOu",
        "colab_type": "text"
      },
      "source": [
        "## Environment Setup\n",
        "\n",
        "The cell below sets up the environment for running the analyses. Run the cell and wait for it to complete. You won't see any text output this time.\n",
        "\n",
        "You probably will not need to call any of the methods defined in this method, and you probably will not need to edit anything in the cell.\n",
        "\n",
        "You **will** need to re-run the cell whenever your notebook connects to a new virtual machine.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ifxh2nzm173",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import os\n",
        "import shutil\n",
        "from tempfile import mkdtemp\n",
        "import urllib.request\n",
        "\n",
        "from IPython.display import HTML\n",
        "import pandas as pd\n",
        "\n",
        "from kndatacleanup import data_cleanup\n",
        "from knfeatureprioritization import feature_prioritization\n",
        "from kngeneprioritization import gene_prioritization\n",
        "from kngenesetcharacterization import geneset_characterization\n",
        "from knsamplesclustering import samples_clustering\n",
        "from kngeneralclustering import general_clustering\n",
        "from knspreadsheetstransformation.spreadsheets_transformation_toolbox import \\\n",
        "    get_cluster_binary_dataframe\n",
        "\n",
        "NETWORK_DIR_PATH = '/network/'\n",
        "\n",
        "REDIS_PARAMS = {\n",
        "    'host': 'knowredis.knoweng.org',\n",
        "    'password': 'KnowEnG',\n",
        "    'port': 6379\n",
        "}\n",
        "\n",
        "NUM_CPUS = 2\n",
        "\n",
        "def fetch_network(edge_file_path):\n",
        "    \"\"\"Given the local path to an edge file, ensures that the edge file exists\n",
        "    on disk, downloading it from AWS if necessary.\n",
        "\n",
        "    Arguments:\n",
        "        edge_file_path (str): The local path to an edge file as found in the\n",
        "            data returned by `get_interaction_networks` and\n",
        "            `get_gene_property_networks`.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    \"\"\"\n",
        "    if not os.path.isfile(edge_file_path):\n",
        "        url = \"https://s3.amazonaws.com/KnowNets/KN-20rep-1706/\" + \\\n",
        "            \"userKN-20rep-1706/\" + edge_file_path[len(NETWORK_DIR_PATH):]\n",
        "        os.makedirs(os.path.dirname(edge_file_path), exist_ok=True)\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            with open(edge_file_path, 'wb') as out_file:\n",
        "                shutil.copyfileobj(response, out_file)\n",
        "\n",
        "def fetch_network_metadata():\n",
        "    \"\"\"Downloads from AWS the network overview metadata files required to\n",
        "    implement the network utility methods.\n",
        "\n",
        "    Arguments:\n",
        "        None\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    \"\"\"\n",
        "    filenames = ['db_contents.txt', 'species_desc.txt', 'edge_type.txt']\n",
        "    for filename in filenames:\n",
        "        out_file_path = os.path.join(NETWORK_DIR_PATH, filename)\n",
        "        if not os.path.isfile(out_file_path):\n",
        "            url = \"https://s3.amazonaws.com/KnowNets/KN-20rep-1706/\" + \\\n",
        "                \"userKN-20rep-1706/\" + filename\n",
        "            with urllib.request.urlopen(url) as response:\n",
        "                with open(out_file_path, 'wb') as out_file:\n",
        "                    shutil.copyfileobj(response, out_file)\n",
        "\n",
        "def get_path_to_newest_file_having_prefix(search_dir_path, prefix):\n",
        "    \"\"\"Finds all files in `search_dir_path` whose name begins with `prefix`.\n",
        "    Returns the newest of these matching files, or returns None if no matching\n",
        "    file exists.\n",
        "\n",
        "    Arguments:\n",
        "        search_dir_path (str): The local path to the directory to search.\n",
        "        prefix (str): The string used to filter the files in `search_dir_path`.\n",
        "\n",
        "    Returns:\n",
        "        str: The path to the newest matching file, or None if no matching files\n",
        "            exist.\n",
        "\n",
        "    \"\"\"\n",
        "    matches = [os.path.join(search_dir_path, name) \\\n",
        "        for name in os.listdir(search_dir_path) \\\n",
        "        if name.startswith(prefix)]\n",
        "    # ensure they're all files\n",
        "    matches = [m for m in matches is os.path.isfile(m)]\n",
        "    return_val = None\n",
        "    if matches:\n",
        "        return_val = sorted(matches, \\\n",
        "            key=lambda path: os.path.getctime(path), reverse=True)[0]\n",
        "    return return_val\n",
        "\n",
        "def get_cleaned_file_path(original_file_path, results_dir_path):\n",
        "    \"\"\"Given the name of a file passed to `kndatacleanup.data_cleanup`,\n",
        "    along with the `results_dir_path` passed to `kndatacleanup.data_cleanup`,\n",
        "    returns the path at which the cleaned version of the input can be found.\n",
        "\n",
        "    Arguments:\n",
        "        original_file_path (str): The path to the file that was passed to\n",
        "            `kndatacleanup.data_cleanup`.\n",
        "        results_dir_path (str): The path to the results directory that was\n",
        "            passed to `kndatacleanup.data_cleanup`.\n",
        "\n",
        "    Returns:\n",
        "        str: The path to the cleaned version of `original_file_path` that was\n",
        "            or would be produced by `kndatacleanup.data_cleanup`.\n",
        "\n",
        "    \"\"\"\n",
        "    original_name = os.path.basename(original_file_path)\n",
        "    original_name_root = os.path.splitext(original_name)[0]\n",
        "    return os.path.join(results_dir_path, original_name_root + \"_ETL.tsv\")\n",
        "\n",
        "def get_gene_map_file_path(original_file_path, results_dir_path):\n",
        "    \"\"\"Given the name of an omics file passed to `kndatacleanup.data_cleanup`,\n",
        "    along with the `results_dir_path` passed to `kndatacleanup.data_cleanup`,\n",
        "    returns the path at which the mapping of gene names to gene identifiers\n",
        "    can be found.\n",
        "\n",
        "    Arguments:\n",
        "        original_file_path (str): The path to the omics file that was passed to\n",
        "            `kndatacleanup.data_cleanup`.\n",
        "        results_dir_path (str): The path to the results directory that was\n",
        "            passed to `kndatacleanup.data_cleanup`.\n",
        "\n",
        "    Returns:\n",
        "        str: The path to the gene-name mapping file that was or would be\n",
        "            produced by `kndatacleanup.data_cleanup`.\n",
        "\n",
        "    \"\"\"\n",
        "    original_name = os.path.basename(original_file_path)\n",
        "    original_name_root = os.path.splitext(original_name)[0]\n",
        "    return os.path.join(results_dir_path, original_name_root + \"_MAP.tsv\")\n",
        "\n",
        "os.makedirs(NETWORK_DIR_PATH, exist_ok=True)\n",
        "fetch_network_metadata()\n",
        "\n",
        "!rm -rf /content/sample_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4DCoKLVwBvT",
        "colab_type": "text"
      },
      "source": [
        "## Knowledge Network Utility Methods\n",
        "\n",
        "The cell below defines several utility methods for working with the knowledge network. These methods are used in the example analyses and might be useful to you in your project. Run the cell and wait for it to complete. It won't produce any text output.\n",
        "\n",
        "You probably will not need to edit anything within the cell.\n",
        "\n",
        "A later cell shows how to use the knowledge network utility methods.\n",
        "\n",
        "You **will** need to re-run the cell whenever your notebook connects to a new virtual machine.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKn3Uxx6rLce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_network_species():\n",
        "    \"\"\"Returns information about the species found in the knowledge network.\n",
        "\n",
        "    Arguments:\n",
        "        None\n",
        "\n",
        "    Returns:\n",
        "        list: A list in which each element is a dictionary. Each dictionary has\n",
        "            keys 'id' (which can be passed to other methods that require a\n",
        "            `species_id`), 'short_latin_name', 'latin_name', 'familiar_name',\n",
        "            and 'group_name'.\n",
        "\n",
        "    \"\"\"\n",
        "    return_val = []\n",
        "    species_file_path = os.path.join(NETWORK_DIR_PATH, 'species_desc.txt')\n",
        "    with open(species_file_path) as csvfile:\n",
        "        for row in csv.reader(csvfile, delimiter='\\t'):\n",
        "            return_val.append({\n",
        "                'id': row[0],\n",
        "                'short_latin_name': row[1],\n",
        "                'latin_name': row[2],\n",
        "                'familiar_name': row[3],\n",
        "                'group_name': row[5]\n",
        "            })\n",
        "    return return_val\n",
        "\n",
        "def display_network_species():\n",
        "    \"\"\"Displays a table of the species found in the knowledge network.\n",
        "\n",
        "    Arguments:\n",
        "        None\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    \"\"\"\n",
        "    html_string = \"<table><tr><th>Familiar Name (Latin Name)</th><th>Species Id</th></tr>\"\n",
        "    for species in get_network_species():\n",
        "        html_string += \"<tr><td>\" + species['familiar_name'] + \" (\" + \\\n",
        "            species['latin_name'] + \")</td><td>\" + species['id'] + \"</td></tr>\"\n",
        "    html_string += \"</table>\"\n",
        "    return HTML(html_string)\n",
        "\n",
        "def get_edge_type_name_to_pretty_name():\n",
        "    \"\"\"Returns a dictionary in which the keys are edge type names and the values\n",
        "    are pretty network names.\n",
        "\n",
        "    Arguments:\n",
        "        None\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary in which the keys are edge type names and the values\n",
        "            are pretty network names.\n",
        "\n",
        "    \"\"\"\n",
        "    return_val = {}\n",
        "    file_path = os.path.join(NETWORK_DIR_PATH, 'edge_type.txt')\n",
        "    with open(file_path) as csvfile:\n",
        "        for row in csv.DictReader(csvfile, delimiter='\\t'):\n",
        "            return_val[row['et_name']] = row['pretty_name']\n",
        "    return return_val\n",
        "\n",
        "def get_interaction_networks(species_id):\n",
        "    \"\"\"Given a `species_id`, returns information about the interaction networks\n",
        "    available in the knowledge network.\n",
        "\n",
        "    Arguments:\n",
        "        species_id (int or str): The id for the species of interest, as returned\n",
        "            by `get_network_species` or displayed by `display_network_species`.\n",
        "\n",
        "    Returns:\n",
        "        list: A list in which each element is a dictionary. Each dictionary has\n",
        "            two keys, 'name' and 'edge_file_path'.\n",
        "\n",
        "    \"\"\"\n",
        "    species_id = str(species_id) # user-friendliness\n",
        "    return_val = []\n",
        "    contents_file_path = os.path.join(NETWORK_DIR_PATH, 'db_contents.txt')\n",
        "    with open(contents_file_path) as csvfile:\n",
        "        edge_type_name_to_pretty_name = get_edge_type_name_to_pretty_name()\n",
        "        for row in csv.DictReader(csvfile, delimiter='\\t'):\n",
        "            if row['n1_type'] == 'Gene' and row['taxon'] == species_id:\n",
        "                return_val.append({\n",
        "                    'name': edge_type_name_to_pretty_name[row['et_name']],\n",
        "                    'edge_file_path': os.path.join(\\\n",
        "                        NETWORK_DIR_PATH, 'Gene', species_id, row['et_name'], \\\n",
        "                        species_id + '.' + row['et_name'] + '.edge')\n",
        "                })\n",
        "    return return_val\n",
        "\n",
        "def display_interaction_networks(species_id):\n",
        "    \"\"\"Given a `species_id`, displays information about the interaction\n",
        "    networks available in the knowledge network.\n",
        "\n",
        "    Arguments:\n",
        "        species_id (int or str): The id for the species of interest, as returned\n",
        "            by `get_network_species` or displayed by `display_network_species`.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    \"\"\"\n",
        "    html_string = \"<table><tr><th>Interaction Network Name</th><th>Edge File Path</th></tr>\"\n",
        "    for network in get_interaction_networks(species_id):\n",
        "        html_string += \"<tr><td>\" + network['name'] + \"</td><td>\" + \\\n",
        "            network['edge_file_path'] + \"</td></tr>\"\n",
        "    html_string += \"</table>\"\n",
        "    return HTML(html_string)\n",
        "\n",
        "def get_gene_property_networks(species_id):\n",
        "    \"\"\"Given a `species_id`, returns information about the gene-property\n",
        "    networks available in the knowledge network.\n",
        "\n",
        "    Arguments:\n",
        "        species_id (int or str): The id for the species of interest, as returned\n",
        "            by `get_network_species` or displayed by `display_network_species`.\n",
        "\n",
        "    Returns:\n",
        "        list: A list in which each element is a dictionary. Each dictionary has\n",
        "            two keys, 'name' and 'edge_file_path'.\n",
        "\n",
        "    \"\"\"\n",
        "    species_id = str(species_id) # user-friendliness\n",
        "    return_val = []\n",
        "    contents_file_path = os.path.join(NETWORK_DIR_PATH, 'db_contents.txt')\n",
        "    with open(contents_file_path) as csvfile:\n",
        "        edge_type_name_to_pretty_name = get_edge_type_name_to_pretty_name()\n",
        "        for row in csv.DictReader(csvfile, delimiter='\\t'):\n",
        "            if row['n1_type'] == 'Property' and row['taxon'] == species_id:\n",
        "                return_val.append({\n",
        "                    'name': edge_type_name_to_pretty_name[row['et_name']],\n",
        "                    'edge_file_path': os.path.join(\\\n",
        "                        NETWORK_DIR_PATH, 'Property', species_id, row['et_name'], \\\n",
        "                        species_id + '.' + row['et_name'] + '.edge')\n",
        "                })\n",
        "    return return_val\n",
        "\n",
        "def display_gene_property_networks(species_id):\n",
        "    \"\"\"Given a `species_id`, displays information about the gene-property\n",
        "    networks available in the knowledge network.\n",
        "\n",
        "    Arguments:\n",
        "        species_id (int or str): The id for the species of interest, as returned\n",
        "            by `get_network_species` or displayed by `display_network_species`.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    \"\"\"\n",
        "    html_string = \"<table><tr><th>Interaction Network Name</th><th>Edge File Path</th></tr>\"\n",
        "    for network in get_gene_property_networks(species_id):\n",
        "        html_string += \"<tr><td>\" + network['name'] + \"</td><td>\" + \\\n",
        "            network['edge_file_path'] + \"</td></tr>\"\n",
        "    html_string += \"</table>\"\n",
        "    return HTML(html_string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVvYGbnRxE-9",
        "colab_type": "text"
      },
      "source": [
        "### Using the Knowledge Network Utility Methods\n",
        "\n",
        "The three cells below show how `display_network_species`, `display_interaction_networks`, and `display_gene_property_networks` can be called to view information about the knowledge network. This information can be useful in configuring analyses, as you'll see later.\n",
        "\n",
        "These methods are based on three other methods defined in the cell above, `get_network_species`, `get_interaction_networks`, and `get_gene_property_networks`. The \"get\" versions return the same information as the \"display\" versions, but the \"get\" versions return it in a format convenient for use in code instead of a format that's easy to read.\n",
        "\n",
        "You **will not** need to re-run these three cells whenever your notebook connects to a new virtual machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSMHjVi6tnNc",
        "colab_type": "code",
        "outputId": "229067ab-0e11-4003-e46a-fd76d3491a34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "source": [
        "# display all species in the knowledge network\n",
        "display_network_species()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table><tr><th>Familiar Name (Latin Name)</th><th>Species Id</th></tr><tr><td>Human (Homo sapiens)</td><td>9606</td></tr><tr><td>Chimpanzee (Pan troglodytes)</td><td>9598</td></tr><tr><td>Cow (Bos taurus)</td><td>9913</td></tr><tr><td>Dog (Canis familiaris)</td><td>9615</td></tr><tr><td>Macaque (Macaca mulatta)</td><td>9544</td></tr><tr><td>Mouse (Mus musculus)</td><td>10090</td></tr><tr><td>Pig (Sus scrofa)</td><td>9823</td></tr><tr><td>Rat (Rattus norvegicus)</td><td>10116</td></tr><tr><td>Chicken (Gallus gallus)</td><td>9031</td></tr><tr><td>Clawed frog (Xenopus tropicalis)</td><td>8364</td></tr><tr><td>Stickleback (Gasterosteus aculeatus)</td><td>69293</td></tr><tr><td>Zebra finch (Taeniopygia guttata)</td><td>59729</td></tr><tr><td>Zebrafish (Danio rerio)</td><td>7955</td></tr><tr><td>Fruitfly (Drosophila melanogaster)</td><td>7227</td></tr><tr><td>Honey bee (Apis mellifera)</td><td>7460</td></tr><tr><td>Mosquito (Aedes aegypti)</td><td>7159</td></tr><tr><td>Roundworm (Caenorhabditis elegans)</td><td>6239</td></tr><tr><td>Thale cress (Arabidopsis thaliana)</td><td>3702</td></tr><tr><td>Water flea (Daphnia pulex)</td><td>6669</td></tr><tr><td>Yeast (Saccharomyces cerevisiae)</td><td>4932</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uep6yYfe83ly",
        "colab_type": "code",
        "outputId": "28f9a762-5c1c-41c9-b751-37a51269a852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        }
      },
      "source": [
        "# display interaction networks for rat (species id 10116)\n",
        "display_interaction_networks('10116')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table><tr><th>Interaction Network Name</th><th>Edge File Path</th></tr><tr><td>Blastp Protein Sequence Similarity</td><td>/network/Gene/10116/blastp_homology/10116.blastp_homology.edge</td></tr><tr><td>Pathway Commons Catalysis Precedes</td><td>/network/Gene/10116/pathcom_catalysis_precedes/10116.pathcom_catalysis_precedes.edge</td></tr><tr><td>Pathway Commons Controls Expression</td><td>/network/Gene/10116/pathcom_controls_expression_of/10116.pathcom_controls_expression_of.edge</td></tr><tr><td>Pathway Commons Controls Phosphorylation</td><td>/network/Gene/10116/pathcom_controls_phosphorylation_of/10116.pathcom_controls_phosphorylation_of.edge</td></tr><tr><td>Pathway Commons Controls State Change</td><td>/network/Gene/10116/pathcom_controls_state_change_of/10116.pathcom_controls_state_change_of.edge</td></tr><tr><td>Pathway Commons In Complex With</td><td>/network/Gene/10116/pathcom_in_complex_with/10116.pathcom_in_complex_with.edge</td></tr><tr><td>PPI Protein Complex Association</td><td>/network/Gene/10116/PPI_association/10116.PPI_association.edge</td></tr><tr><td>PPI Colocalization</td><td>/network/Gene/10116/PPI_colocalization/10116.PPI_colocalization.edge</td></tr><tr><td>PPI Direct Interaction</td><td>/network/Gene/10116/PPI_direct_interaction/10116.PPI_direct_interaction.edge</td></tr><tr><td>PPI Genetic Interaction</td><td>/network/Gene/10116/PPI_genetic_interaction/10116.PPI_genetic_interaction.edge</td></tr><tr><td>PPI Physical Association</td><td>/network/Gene/10116/PPI_physical_association/10116.PPI_physical_association.edge</td></tr><tr><td>Reactome PPI Direct Complex</td><td>/network/Gene/10116/reactome_PPI_direct_complex/10116.reactome_PPI_direct_complex.edge</td></tr><tr><td>Reactome PPI Indirect Complex</td><td>/network/Gene/10116/reactome_PPI_indirect_complex/10116.reactome_PPI_indirect_complex.edge</td></tr><tr><td>Reactome PPI Reaction Partners</td><td>/network/Gene/10116/reactome_PPI_reaction/10116.reactome_PPI_reaction.edge</td></tr><tr><td>STRING Co-expression</td><td>/network/Gene/10116/STRING_coexpression/10116.STRING_coexpression.edge</td></tr><tr><td>STRING Functional Databases</td><td>/network/Gene/10116/STRING_database/10116.STRING_database.edge</td></tr><tr><td>STRING Experimental PPI</td><td>/network/Gene/10116/STRING_experimental/10116.STRING_experimental.edge</td></tr><tr><td>STRING Gene Fusion Event</td><td>/network/Gene/10116/STRING_fusion/10116.STRING_fusion.edge</td></tr><tr><td>STRING Proximal Neighborhood</td><td>/network/Gene/10116/STRING_neighborhood/10116.STRING_neighborhood.edge</td></tr><tr><td>STRING Text Mining from Abstracts</td><td>/network/Gene/10116/STRING_textmining/10116.STRING_textmining.edge</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNl8XB-T84x5",
        "colab_type": "code",
        "outputId": "6e80553e-b279-4275-97b0-1cc88d7b3036",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# display gene property networks for roundworm (species id 6239)\n",
        "display_gene_property_networks('6239')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table><tr><th>Interaction Network Name</th><th>Edge File Path</th></tr><tr><td>Gene Ontology</td><td>/network/Property/6239/gene_ontology/6239.gene_ontology.edge</td></tr><tr><td>Pathway Commons Pathways</td><td>/network/Property/6239/pathcom_pathway/6239.pathcom_pathway.edge</td></tr><tr><td>PFam Prot Domains</td><td>/network/Property/6239/pfam_prot/6239.pfam_prot.edge</td></tr><tr><td>Reactome Pathways Curated</td><td>/network/Property/6239/reactome_annotation/6239.reactome_annotation.edge</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmTUV9Lp_rK0",
        "colab_type": "text"
      },
      "source": [
        "## Analytics Methods\n",
        "\n",
        "The cell below defines methods for running clustering, prioritization, and gene-set characterization. Run the cell and wait for it to complete. It won't produce any output.\n",
        "\n",
        "You **will** need to re-run the cell whenever your notebook connects to a new virtual machine.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M6MGR3K_pd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def do_clustering(\\\n",
        "    omics_file_path, phenotype_file_path, results_dir_path, num_clusters, \\\n",
        "    species_id, interaction_network_edge_file_path, network_influence, \\\n",
        "    num_bootstraps, bootstrap_sample_fraction):\n",
        "    \"\"\"Performs a clustering upon the samples found in `omics_file_path`.\n",
        "\n",
        "    Arguments:\n",
        "        omics_file_path (str): The path to the omics file.\n",
        "        phenotype_file_path (str): The path to a file containing phenotype data\n",
        "            on the same samples as found in `omics_file_path`, or None if no\n",
        "            phenotype data are to be analyzed. If analyzed, each phenotype will\n",
        "            scored for statistically significant differences between the\n",
        "            clusters.\n",
        "        results_dir_path (str): The path to a directory where results files\n",
        "            should be stored.\n",
        "        num_clusters (int): The number of clusters to create.\n",
        "        species_id (int or str): The id for the species of interest, as returned\n",
        "            by `get_network_species` or displayed by `display_network_species`,\n",
        "            or None not using an `interaction_network_edge_file_path`.\n",
        "        interaction_network_edge_file_path (str): The path to an interaction\n",
        "            network edge file, to use a knowledge-guided approach to clustering,\n",
        "            or else None.\n",
        "        network_influence (float): A number between 0 and 1 that specifies the\n",
        "            amount to which network data should influence the results, or None\n",
        "            if not using an `interaction_network_edge_file_path`.\n",
        "        num_bootstraps (int): A number of bootstrap iterations to run. Use 0 for\n",
        "            no bootstrapping.\n",
        "        bootstrap_sample_fraction (float): A number between 0 and 1 that\n",
        "            specifies what fraction of the data should be used in each bootstrap\n",
        "            iteration, or None if not using bootstrapping.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    \"\"\"\n",
        "    species_id = str(species_id) # user-friendliness\n",
        "    os.makedirs(results_dir_path, exist_ok=True)\n",
        "\n",
        "    if interaction_network_edge_file_path is None:\n",
        "        pipeline_type = 'general_clustering_pipeline'\n",
        "    else:\n",
        "        fetch_network(interaction_network_edge_file_path)\n",
        "        pipeline_type = 'samples_clustering_pipeline'\n",
        "\n",
        "    cleanup_parameters = {\n",
        "        'spreadsheet_name_full_path': omics_file_path,\n",
        "        'pipeline_type': pipeline_type,\n",
        "        'results_directory': results_dir_path\n",
        "    }\n",
        "    if phenotype_file_path is not None:\n",
        "        cleanup_parameters['phenotype_name_full_path'] = phenotype_file_path\n",
        "    if interaction_network_edge_file_path is not None:\n",
        "        cleanup_parameters.update({\n",
        "            'gg_network_name_full_path': interaction_network_edge_file_path,\n",
        "            'taxonid': species_id,\n",
        "            'source_hint': '',\n",
        "            'redis_credential': {\n",
        "                'host': REDIS_PARAMS['host'],\n",
        "                'port': REDIS_PARAMS['port'],\n",
        "                'password': REDIS_PARAMS['password']\n",
        "            }\n",
        "        })\n",
        "    data_cleanup.run_pipelines(cleanup_parameters, \\\n",
        "        data_cleanup.SELECT[pipeline_type])\n",
        "\n",
        "    clustering_parameters = {\n",
        "        'spreadsheet_name_full_path': get_cleaned_file_path(\\\n",
        "            omics_file_path, results_dir_path),\n",
        "        'results_directory': results_dir_path,\n",
        "        'processing_method': 'parallel',\n",
        "        'parallelism': NUM_CPUS,\n",
        "        'number_of_clusters': num_clusters,\n",
        "        'run_directory': results_dir_path,\n",
        "        'tmp_directory': './tmp'\n",
        "    }\n",
        "    if phenotype_file_path is not None:\n",
        "        clustering_parameters.update({\n",
        "            'phenotype_name_full_path': get_cleaned_file_path(\\\n",
        "                phenotype_file_path, results_dir_path),\n",
        "            'threshold': 15\n",
        "        })\n",
        "\n",
        "    method_prefix = ''\n",
        "    if num_bootstraps > 0:\n",
        "        clustering_parameters.update({\n",
        "            'number_of_bootstraps': num_bootstraps,\n",
        "            'rows_sampling_fraction': 1.0,\n",
        "            'cols_sampling_fraction': bootstrap_sample_fraction\n",
        "        })\n",
        "        method_prefix = 'cc_'\n",
        "\n",
        "    if interaction_network_edge_file_path is not None:\n",
        "        clustering_parameters.update({\n",
        "            'gg_network_name_full_path': interaction_network_edge_file_path,\n",
        "            'rwr_max_iterations': 100,\n",
        "            'rwr_convergence_tolerence': 1.0e-4,\n",
        "            'rwr_restart_probability': network_influence,\n",
        "            'top_number_of_genes': 100,\n",
        "            'nmf_conv_check_freq': 50,\n",
        "            'nmf_max_invariance': 200,\n",
        "            'nmf_max_iterations': 10000,\n",
        "            'nmf_penalty_parameter': 1400,\n",
        "            'method': method_prefix + 'net_nmf'\n",
        "        })\n",
        "        samples_clustering.SELECT[clustering_parameters['method']](\\\n",
        "            clustering_parameters)\n",
        "    else:\n",
        "        clustering_parameters.update({\n",
        "            'top_number_of_rows': 100,\n",
        "            'affinity_metric': 'euclidean',\n",
        "            'linkage_criterion': 'ward',\n",
        "            'method': method_prefix + 'hclust'\n",
        "        })\n",
        "        general_clustering.SELECT[clustering_parameters['method']](\\\n",
        "            clustering_parameters)\n",
        "\n",
        "def do_prioritization(\\\n",
        "    omics_file_path, phenotype_file_path, results_dir_path, \\\n",
        "    correlation_measure, missing_value_strategy, num_exported_features, \\\n",
        "    num_response_correlated_features, species_id, \\\n",
        "    interaction_network_edge_file_path, network_influence):\n",
        "    \"\"\"Prioritizes the features (genes or otherwise) found in `omics_file_path`\n",
        "    for each phenotype found in `phenotype_file_path`.\n",
        "\n",
        "    Arguments:\n",
        "        omics_file_path (str): The path to the omics file.\n",
        "        phenotype_file_path (str): The path to a file containing phenotype data\n",
        "            on the same samples as found in `omics_file_path`.\n",
        "        results_dir_path (str): The path to a directory where results files\n",
        "            should be stored.\n",
        "        correlation_measure (str): Either 't_test' for binary or categorical\n",
        "            phenotypes or 'pearson' for numeric phenotypes.\n",
        "        missing_value_strategy (str): Governs how to handle missing values in\n",
        "            `omics_file_path`. Options are 'average' to use the average value\n",
        "            for the feature among the other samples, 'remove' to drop any\n",
        "            samples with missing values, or 'reject' to fail if any missing\n",
        "            values are found (perhaps as a sanity check if you believe missing\n",
        "            values were prevented upstream).\n",
        "        num_exported_features (int): The number of top features per phenotype to\n",
        "            include in the matrix that can be passed to `do_characterization`.\n",
        "        num_response_correlated_features (int): The number of top features to\n",
        "            retain from the first stage of the analysis if using an\n",
        "            `interaction_network_edge_file_path`.\n",
        "        species_id (int or str): The id for the species of interest, as returned\n",
        "            by `get_network_species` or displayed by `display_network_species`,\n",
        "            or none if not using an `interactive_network_edge_file_path`.\n",
        "        interaction_network_edge_file_path (str): The path to an interaction\n",
        "            network edge file, to use a knowledge-guided approach to\n",
        "            prioritization, or else None.\n",
        "        network_influence (float): A number between 0 and 1 that specifies the\n",
        "            amount to which network data should influence the results, or None\n",
        "            if not using an `interaction_network_edge_file_path`.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    \"\"\"\n",
        "    species_id = str(species_id) # user-friendliness\n",
        "    os.makedirs(results_dir_path, exist_ok=True)\n",
        "\n",
        "    if interaction_network_edge_file_path is None:\n",
        "        pipeline_type = 'feature_prioritization_pipeline'\n",
        "    else:\n",
        "        fetch_network(interaction_network_edge_file_path)\n",
        "        pipeline_type = 'gene_prioritization_pipeline'\n",
        "\n",
        "    cleanup_parameters = {\n",
        "        'spreadsheet_name_full_path': omics_file_path,\n",
        "        'phenotype_name_full_path': phenotype_file_path,\n",
        "        'pipeline_type': pipeline_type,\n",
        "        'correlation_measure': correlation_measure, # t_test, pearson, edgeR\n",
        "        'impute': missing_value_strategy, # average, remove, reject\n",
        "        'results_directory': results_dir_path\n",
        "    }\n",
        "    if interaction_network_edge_file_path is not None:\n",
        "        cleanup_parameters.update({\n",
        "            'taxonid': species_id,\n",
        "            'source_hint': '',\n",
        "            'redis_credential': {\n",
        "                    'host': REDIS_PARAMS['host'],\n",
        "                    'port': REDIS_PARAMS['port'],\n",
        "                    'password': REDIS_PARAMS['password']\n",
        "            }\n",
        "        })\n",
        "    data_cleanup.run_pipelines(cleanup_parameters, \\\n",
        "        data_cleanup.SELECT[pipeline_type])\n",
        "\n",
        "    prioritization_parameters = {\n",
        "        'correlation_measure': correlation_measure,\n",
        "        'spreadsheet_name_full_path': get_cleaned_file_path(\\\n",
        "            omics_file_path, results_dir_path),\n",
        "        'phenotype_name_full_path': get_cleaned_file_path(\\\n",
        "            phenotype_file_path, results_dir_path),\n",
        "        'results_directory': results_dir_path,\n",
        "        'top_gamma_of_sort': num_exported_features,\n",
        "        'max_cpu': NUM_CPUS\n",
        "    }\n",
        "    if interaction_network_edge_file_path is not None:\n",
        "        prioritization_parameters.update({\n",
        "            'gg_network_name_full_path': interaction_network_edge_file_path,\n",
        "            'rwr_max_iterations': 100,\n",
        "            'rwr_convergence_tolerence': 1.0e-4,\n",
        "            'rwr_restart_probability': network_influence,\n",
        "            'top_beta_of_sort': num_response_correlated_features,\n",
        "            'method': 'net_correlation'\n",
        "        })\n",
        "        gene_prioritization.net_correlation(prioritization_parameters)\n",
        "    else:\n",
        "        prioritization_parameters.update({\n",
        "            'top_beta_of_sort': num_exported_features,\n",
        "            'method': 'correlation',\n",
        "        })\n",
        "        feature_prioritization.correlation(prioritization_parameters)\n",
        "\n",
        "def do_characterization(\\\n",
        "    gene_matrix_file_path, results_dir_path, species_id, \\\n",
        "    gene_property_edge_file_path, interaction_network_edge_file_path, \\\n",
        "    network_influence):\n",
        "    \"\"\"Compares user-submitted gene sets to those found in a gene-property\n",
        "    network from the knowledge network.\n",
        "\n",
        "    Arguments:\n",
        "        gene_matrix_file_path (str): The path to the gene matrix that defines\n",
        "            one or more gene sets.\n",
        "        results_dir_path (str): The path to a directory where results files\n",
        "            should be stored.\n",
        "        species_id (int or str): The id for the species of interest, as returned\n",
        "            by `get_network_species` or displayed by `display_network_species`.\n",
        "        gene_property_edge_file_path: The path to a gene-property network edge\n",
        "            file.\n",
        "        interaction_network_edge_file_path (str): The path to an interaction\n",
        "            network edge file, to use a knowledge-guided approach to\n",
        "            characterization, or else None.\n",
        "        network_influence (float): A number between 0 and 1 that specifies the\n",
        "            amount to which network data should influence the results, or None\n",
        "            if not using an `interaction_network_edge_file_path`.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "\n",
        "    \"\"\"\n",
        "    species_id = str(species_id) # user-friendliness\n",
        "    os.makedirs(results_dir_path, exist_ok=True)\n",
        "\n",
        "    fetch_network(gene_property_edge_file_path)\n",
        "\n",
        "    cleanup_parameters = {\n",
        "        'spreadsheet_name_full_path': gene_matrix_file_path,\n",
        "        'pipeline_type': 'geneset_characterization_pipeline',\n",
        "        'results_directory': results_dir_path,\n",
        "        'taxonid': species_id,\n",
        "        'source_hint': '',\n",
        "        'redis_credential': {\n",
        "            'host': REDIS_PARAMS['host'],\n",
        "            'port': REDIS_PARAMS['port'],\n",
        "            'password': REDIS_PARAMS['password']\n",
        "        }\n",
        "    }\n",
        "    data_cleanup.run_pipelines(cleanup_parameters, \\\n",
        "        data_cleanup.SELECT['geneset_characterization_pipeline'])\n",
        "\n",
        "    characterization_parameters = {\n",
        "        'spreadsheet_name_full_path': get_cleaned_file_path(\\\n",
        "            gene_matrix_file_path, results_dir_path),\n",
        "        'gene_names_map': get_gene_map_file_path(\\\n",
        "            gene_matrix_file_path, results_dir_path),\n",
        "        'results_directory': results_dir_path,\n",
        "        'pg_network_name_full_path': gene_property_edge_file_path,\n",
        "        'max_cpu': NUM_CPUS\n",
        "    }\n",
        "    if interaction_network_edge_file_path is None:\n",
        "        characterization_parameters.update({\n",
        "            'method': 'fisher'\n",
        "        })\n",
        "        geneset_characterization.fisher(characterization_parameters)\n",
        "    else:\n",
        "        fetch_network(interaction_network_edge_file_path)\n",
        "        characterization_parameters.update({\n",
        "            'method': 'DRaWR',\n",
        "            'rwr_max_iterations': 500,\n",
        "            'rwr_convergence_tolerence': 1.0e-4,\n",
        "            'rwr_restart_probability': network_influence,\n",
        "            'gg_network_name_full_path': interaction_network_edge_file_path\n",
        "        })\n",
        "        geneset_characterization.DRaWR(characterization_parameters)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRxFpjpTM0b8",
        "colab_type": "text"
      },
      "source": [
        "## Connect to Google Drive\n",
        "\n",
        "The cell below enables this notebook to use your Google Drive for file storage. Subsequent cells will use this access to load the example files you copied earlier and to save results of the example analyses. You might also find this helpful in running your own analyses.\n",
        "\n",
        "Run the cell and click on the link that appears in the output. On the linked page, select your illinois.edu account and grant the requested permissions. The page will then display a code. Copy the code and paste it in the box that appears in the output below. Then press Enter.\n",
        "\n",
        "You **will** need to re-run the cell whenever your notebook connects to a new virtual machine.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTqz9ZNXvlG_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "5a5fde70-683d-4b11-feba-998a7795bb5c"
      },
      "source": [
        "from google.colab import drive\n",
        "GDRIVE_MOUNT_PATH = '/content/gdrive'\n",
        "drive.mount(GDRIVE_MOUNT_PATH)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC9dFiPKnLmv",
        "colab_type": "text"
      },
      "source": [
        "## Setting File Locations\n",
        "\n",
        "In the cell below, we will tell the notebook where the example files can be found and where the results should be saved.\n",
        "\n",
        "To confirm the location, find the arrow symbol (>) near the top left corner of the portion of your screen that shows the notebook content. Click it to reveal a panel with three tabs labeled `Table of contents`, `Code snippets`, and `Files`. Click on the `Files` tab.\n",
        "\n",
        "In the `Files` tab, you should see one folder named `gdrive`. Click the arrow next to the `gdrive` folder to expand it, and continue navigating through the folders until you find the `example_analyses` folder copied previously. Right-click on `example_analyses` and select `Copy path`. Paste the value into the cell below, and compare it to the value assigned to `INPUT_DATA_DIR_PATH`. If the values are different, replace the pre-coded value with the one you pasted. Once you have done that, run the cell.\n",
        "\n",
        "If at any point you open the `Files` tab or click its `REFRESH` button and do not see `gdrive`, you might need to re-run the previous cell.\n",
        "\n",
        "Note this cell also specifies the output directories that will be used for the different analyses in the example. They are defined here, in the last quick-running cell before the analyses below, because the variables will need to be refreshed if your notebook connects to a new virtual machine.\n",
        "\n",
        "You **will** need to re-run the cell whenever your notebook connects to a new virtual machine, but the value assigned to `INPUT_DATA_DIR_PATH` will not change unless you move the folder within your Google Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnBOrd8rMm2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DATA_DIR_PATH = '/content/gdrive/My Drive/College of Medicine Data Science Project/Genomics/example_analyses'\n",
        "OUTPUT_DATA_DIR_PATH = os.path.join(INPUT_DATA_DIR_PATH, 'results')\n",
        "\n",
        "CLUSTERING1_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'clustering1')\n",
        "CLUSTERING2_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'clustering2')\n",
        "CLUSTERING3_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'clustering3')\n",
        "CLUSTERING4_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'clustering4')\n",
        "CLUSTERING5_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'clustering5')\n",
        "CLUSTERING6_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'clustering6')\n",
        "\n",
        "PRIORITIZATION1_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'prioritization1')\n",
        "PRIORITIZATION2_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'prioritization2')\n",
        "PRIORITIZATION3_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'prioritization3')\n",
        "\n",
        "CHARACTERIZATION1_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'characterization1')\n",
        "CHARACTERIZATION2_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'characterization2')\n",
        "CHARACTERIZATION3_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'characterization3')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t-CbUY6sP2K",
        "colab_type": "text"
      },
      "source": [
        "## Clustering\n",
        "\n",
        "The following four cells will use standard clustering techniques to group samples according to different omics data. Run each cell; note each will take several minutes. You'll see some output describing the inputs and results.\n",
        "\n",
        "As each of these cells finishes, it will store the results to your Google Drive. For that reason, you **will not** need to re-run these cells whenever your notebook connects to a new virtual machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub32Jwwksg31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "do_clustering(\\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_clustering1_genecopynumber.tsv'), \\\n",
        "    None, CLUSTERING1_DIR_PATH, 8, None, None, None, 0, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKX0UCvmskVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "do_clustering(\\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_clustering2_exp_HiSeqV2.tsv'), \\\n",
        "    None, CLUSTERING2_DIR_PATH, 13, None, None, None, 0, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV7S9H7FsngW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "do_clustering(\\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_clustering3_hMethyl.tsv'), \\\n",
        "    None, CLUSTERING3_DIR_PATH, 19, None, None, None, 0, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFJcuLclspo5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "do_clustering(\\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_clustering4_RPPA_RBN.tsv'), \\\n",
        "    None, CLUSTERING4_DIR_PATH, 8, None, None, None, 0, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWMbtPJZssUT",
        "colab_type": "text"
      },
      "source": [
        "### Network-Based Clustering\n",
        "\n",
        "This fifth clustering analysis incorporates the knowledge network in order to improve results over sparse omics data. As with the above clustering analyses, run the cell and wait until it completes.\n",
        "\n",
        "As with all of the analysis cells, it will store the results to your Google Drive. For that reason, you **will not** need to re-run this cell whenever your notebook connects to a new virtual machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mnPXgrTss9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "do_clustering(\\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_clustering5_mutation.tsv'), \\\n",
        "    None, CLUSTERING5_DIR_PATH, 14, '9606', \\\n",
        "    '/network/Gene/9606/hn_IntNet/9606.hn_IntNet.edge', 0.5, 0, None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwpR_2p-bwjo",
        "colab_type": "text"
      },
      "source": [
        "### Cluster-of-Clusters Analysis (COCA)\n",
        "\n",
        "This sixth clustering analysis operates upon the cluster assignments generated by the previous five clustering analyses. Again, run the cell and wait until it finishes.\n",
        "\n",
        "As with all of the analysis cells, it will store the results to your Google Drive. For that reason, you **will not** need to re-run this cell whenever your notebook connects to a new virtual machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8Kdpf2McHdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gather the outputs from the five previous clustering analyses\n",
        "raw_coca_inputs = [\n",
        "    get_path_to_newest_file_having_prefix(CLUSTERING1_DIR_PATH, 'samples_label_by_cluster'),\n",
        "    get_path_to_newest_file_having_prefix(CLUSTERING2_DIR_PATH, 'samples_label_by_cluster'),\n",
        "    get_path_to_newest_file_having_prefix(CLUSTERING3_DIR_PATH, 'samples_label_by_cluster'),\n",
        "    get_path_to_newest_file_having_prefix(CLUSTERING4_DIR_PATH, 'samples_label_by_cluster'),\n",
        "    get_path_to_newest_file_having_prefix(CLUSTERING5_DIR_PATH, 'samples_label_by_cluster')\n",
        "]\n",
        "\n",
        "# assemble the raw inputs into a single file formatted like an omics file\n",
        "coca_input_file_path = os.path.join(CLUSTERING6_DIR_PATH, 'input.tsv')\n",
        "temp_dir_path = mkdtemp()\n",
        "for input in raw_coca_inputs:\n",
        "    shutil.copy(input, temp_dir_path)\n",
        "coca_input_df = get_cluster_binary_dataframe(\\\n",
        "    [os.path.basename(input) for input in raw_coca_inputs], temp_dir_path).T\n",
        "coca_input_df.to_csv(coca_input_file_path, sep='\\t')\n",
        "shutil.rmtree(temp_dir_path)\n",
        "\n",
        "do_clustering(\\\n",
        "    coca_input_file_path, \\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_clustering_clinical_data.tsv'), \\\n",
        "    CLUSTERING6_DIR_PATH, 13, None, None, None, 200, 0.8)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icBaJd0bG5eU",
        "colab_type": "text"
      },
      "source": [
        "We can also perform a survival analysis on the identified clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU2YPY6TG4xJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the file containing the clinical data\n",
        "# survival data are found in columns _OS_IND (boolean representing event) and\n",
        "# _OS (float indicating time)\n",
        "phenotype_df = pd.read_csv(\\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_clustering_clinical_data.tsv'), \\\n",
        "    sep='\\t', index_col=0, header=0)\n",
        "\n",
        "# load the cluster assignments\n",
        "cluster_labels_file_path = get_path_to_newest_file_having_prefix(\\\n",
        "    CLUSTERING6_DIR_PATH, 'samples_label_by_cluster')\n",
        "cluster_labels_df = pd.read_csv(cluster_labels_file_path, \\\n",
        "    sep='\\t', index_col=0, header=0)\n",
        "# reorder cluster_labels_df to match the sample order in phenotype_df\n",
        "cluster_labels_df = cluster_labels_df.reindex(phenotype_df.index)\n",
        "cluster_labels_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mRscDmTd9UF",
        "colab_type": "text"
      },
      "source": [
        "## Gene Prioritization\n",
        "\n",
        "The following three cells will analyze gene expression data to determine the genes most associated with phenotypes of interest.\n",
        "\n",
        "In the first of the three prioritization cells, the phenotypes are PANCAN disease types, and the method is a standard prioritization technique. Run the cell and wait until it finishes.\n",
        "\n",
        "As with all of the analysis cells, it will store the results to your Google Drive. For that reason, you **will not** need to re-run this cell whenever your notebook connects to a new virtual machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTXqLBcSfOgj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "do_prioritization(\\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_prioritization_expr.tsv'), \\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'pancan_disease_types.gXc'), \\\n",
        "    PRIORITIZATION1_DIR_PATH, 't_test', 'average', 100, 50, None, None, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNkmEKAbfq7l",
        "colab_type": "text"
      },
      "source": [
        "In the second of the three prioritization cells, the phenotypes are again the PANCAN disease types, but the method incorporates the knowledge network. Again, run the cell and wait until it finishes.\n",
        "\n",
        "As with all of the analysis cells, it will store the results to your Google Drive. For that reason, you **will not** need to re-run this cell whenever your notebook connects to a new virtual machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dugvbIPxgBkq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "do_prioritization(\\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_prioritization_expr.tsv'), \\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'pancan_disease_types.gXc'), \\\n",
        "    PRIORITIZATION2_DIR_PATH, 't_test', 'average', 100, 50, '9606', \\\n",
        "    '/network/Gene/9606/hn_IntNet/9606.hn_IntNet.edge', 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn1YlqtogXoX",
        "colab_type": "text"
      },
      "source": [
        "In the third of the three prioritization cells, the phenotypes are the COCA cluster assignments. The standard method is used.\n",
        "\n",
        "Run the cell and wait until it finishes.\n",
        "\n",
        "As with all of the analysis cells, it will store the results to your Google Drive. For that reason, you **will not** need to re-run this cell whenever your notebook connects to a new virtual machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9E9efqLgnUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "do_prioritization(\\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_prioritization_expr.tsv'), \\\n",
        "    get_path_to_newest_file_having_prefix(CLUSTERING6_DIR_PATH, 'samples_label_by_cluster'), \\\n",
        "    PRIORITIZATION3_DIR_PATH, 't_test', 'average', 100, 50, None, None, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWH5pdx8lVhh",
        "colab_type": "text"
      },
      "source": [
        "## Gene-Set Characterization\n",
        "\n",
        "The final three cells compare the top genes found by the gene prioritization analyses with gene sets from the Gene Ontology database and a set of known cancer drivers.\n",
        "\n",
        "Each cell in this sequence corresponds to one of the three gene prioritization analyses above. Run each cell and wait for it to finish.\n",
        "\n",
        "As with all of the analysis cells, these will store the results to your Google Drive. For that reason, you **will not** need to re-run these cells whenever your notebook connects to a new virtual machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqoPge_4mcHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for property_edge_file_path in [\\\n",
        "        '/network/Property/9606/gene_ontology/9606.gene_ontology.edge', \\\n",
        "        '/network/Property/9606/cancer_driver_genes/9606.cancer_driver_genes.edge']:\n",
        "    do_characterization(\\\n",
        "        get_path_to_newest_file_having_prefix(PRIORITIZATION1_DIR_PATH, 'top_'), \\\n",
        "        CHARACTERIZATION1_DIR_PATH, '9606', property_edge_file_path, None, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEyycIpIFa9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for property_edge_file_path in [\\\n",
        "        '/network/Property/9606/gene_ontology/9606.gene_ontology.edge', \\\n",
        "        '/network/Property/9606/cancer_driver_genes/9606.cancer_driver_genes.edge']:\n",
        "    do_characterization(\\\n",
        "        get_path_to_newest_file_having_prefix(PRIORITIZATION2_DIR_PATH, 'top_'), \\\n",
        "        CHARACTERIZATION2_DIR_PATH, '9606', property_edge_file_path, None, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGDg9MiMFepB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for property_edge_file_path in [\\\n",
        "        '/network/Property/9606/gene_ontology/9606.gene_ontology.edge', \\\n",
        "        '/network/Property/9606/cancer_driver_genes/9606.cancer_driver_genes.edge']:\n",
        "    do_characterization(\\\n",
        "        get_path_to_newest_file_having_prefix(PRIORITIZATION3_DIR_PATH, 'top_'), \\\n",
        "        CHARACTERIZATION3_DIR_PATH, '9606', property_edge_file_path, None, None)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}