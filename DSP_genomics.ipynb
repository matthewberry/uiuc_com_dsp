{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSP genomics.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthewberry/uiuc_com_dsp/blob/master/DSP_genomics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZlQjjAmJuSY",
        "colab_type": "text"
      },
      "source": [
        "## Using This Notebook\n",
        "\n",
        "This notebook is an interactive environment that combines explanatory text with executable code. It provides computational tools useful in genomics, and you will familiarize yourself with them by stepping through a series of analyses that examine related data sets from multiple angles. This suite of tools and example can then serve as a starting point for a project of your own design.\n",
        "\n",
        "If you are new to notebooks, you might find this introduction helpful: [Overview of Colaboratory Features](https://colab.research.google.com/notebooks/basic_features_overview.ipynb) You might also want to refer to the [Python 3 documentation](https://docs.python.org/3/).\n",
        "\n",
        "Note that after a period of inactivity, Google will disconnect your notebook from the virtual machine that had been running it. When you return, Google will connect to a new virtual machine. Any data files you saved to your Google Drive will remain, but any variables or methods defined in your previous virtual machine will have to be reloaded. (You will know when this happens, because cells that previously ran without error will suddenly stop working.) To reload the variable and method definitions, you can simply re-run the cells where they're defined. This notebook will explain which cells might need to be re-run.\n",
        "\n",
        "Prep to document:\n",
        "* enable google apps\n",
        "* sign in to illinois google account\n",
        "* open this notebook\n",
        "* File -> Save a copy in Drive (and then File -> Locate in Drive to see where it's being saved; can return there to open it later if you need to)\n",
        "* open data dir\n",
        "* save to my drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RczciUOYuOzp",
        "colab_type": "text"
      },
      "source": [
        "## Installation\n",
        "\n",
        "The cell below installs software required to perform the analyses. Run the cell and wait for it to complete, which might take several minutes. You'll see lots of text output as the cell runs, but there's no need to read it unless the following cell fails.\n",
        "\n",
        "You **will** need to re-run this cell whenever your notebook connects to a new virtual machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgrIxPJT-UiT",
        "colab_type": "code",
        "outputId": "a0d37f50-d079-40d6-d509-49eb3237e62e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip3 install -I pyyaml==5.1.2\n",
        "!pip3 install xmlrunner==1.7.7 redis==3.3.8 lifelines==0.22.8\n",
        "!pip3 install git+https://github.com/KnowEnG/KnowEnG_Pipelines_Library.git@mjberry/update_dependencies\n",
        "!pip3 install git+https://github.com/KnowEnG/Data_Cleanup_Pipeline.git@mjberry/create_package\n",
        "!pip3 install git+https://github.com/KnowEnG/General_Clustering_Pipeline.git@mjberry/create_package\n",
        "!pip3 install git+https://github.com/KnowEnG/Samples_Clustering_Pipeline.git@mjberry/create_package\n",
        "!pip3 install git+https://github.com/KnowEnG/Feature_Prioritization_Pipeline.git@mjberry/create_package\n",
        "!pip3 install git+https://github.com/KnowEnG/Gene_Prioritization_Pipeline.git@mjberry/create_package\n",
        "!pip3 install git+https://github.com/KnowEnG/Geneset_Characterization_Pipeline.git@mjberry/create_package\n",
        "!pip3 install git+https://github.com/KnowEnG/Spreadsheets_Transformation.git@mjberry/create_package"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyyaml==5.1.2\n",
            "Installing collected packages: pyyaml\n",
            "Successfully installed pyyaml-5.1.2\n",
            "Requirement already satisfied: xmlrunner==1.7.7 in /usr/local/lib/python3.6/dist-packages (1.7.7)\n",
            "Requirement already satisfied: redis==3.3.8 in /usr/local/lib/python3.6/dist-packages (3.3.8)\n",
            "Requirement already satisfied: lifelines==0.22.8 in /usr/local/lib/python3.6/dist-packages (0.22.8)\n",
            "Requirement already satisfied: autograd-gamma>=0.3 in /usr/local/lib/python3.6/dist-packages (from lifelines==0.22.8) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from lifelines==0.22.8) (1.17.2)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from lifelines==0.22.8) (0.25.1)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.6/dist-packages (from lifelines==0.22.8) (3.1.1)\n",
            "Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.6/dist-packages (from lifelines==0.22.8) (1.3)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from lifelines==0.22.8) (1.3.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->lifelines==0.22.8) (2019.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->lifelines==0.22.8) (2.8.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->lifelines==0.22.8) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->lifelines==0.22.8) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0->lifelines==0.22.8) (2.4.2)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from autograd>=1.3->lifelines==0.22.8) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.23.0->lifelines==0.22.8) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.0->lifelines==0.22.8) (41.4.0)\n",
            "Collecting git+https://github.com/KnowEnG/KnowEnG_Pipelines_Library.git@mjberry/update_dependencies\n",
            "  Cloning https://github.com/KnowEnG/KnowEnG_Pipelines_Library.git (to revision mjberry/update_dependencies) to /tmp/pip-req-build-5k1lfa0k\n",
            "  Running command git clone -q https://github.com/KnowEnG/KnowEnG_Pipelines_Library.git /tmp/pip-req-build-5k1lfa0k\n",
            "  Running command git checkout -b mjberry/update_dependencies --track origin/mjberry/update_dependencies\n",
            "  Switched to a new branch 'mjberry/update_dependencies'\n",
            "  Branch 'mjberry/update_dependencies' set up to track remote branch 'mjberry/update_dependencies' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): knpackage==0.1.27 from git+https://github.com/KnowEnG/KnowEnG_Pipelines_Library.git@mjberry/update_dependencies in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: knpackage\n",
            "  Building wheel for knpackage (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for knpackage: filename=knpackage-0.1.27-cp36-none-any.whl size=14881 sha256=d6175f925beb654a74903cb8234c7ce10862a85019ee9b73826c338481d67607\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k89wfunl/wheels/70/c7/a1/ea0fd56a8738fc7ac1be0a105130930146120499fdc6606cb9\n",
            "Successfully built knpackage\n",
            "Collecting git+https://github.com/KnowEnG/Data_Cleanup_Pipeline.git@mjberry/create_package\n",
            "  Cloning https://github.com/KnowEnG/Data_Cleanup_Pipeline.git (to revision mjberry/create_package) to /tmp/pip-req-build-f960olu2\n",
            "  Running command git clone -q https://github.com/KnowEnG/Data_Cleanup_Pipeline.git /tmp/pip-req-build-f960olu2\n",
            "  Running command git checkout -b mjberry/create_package --track origin/mjberry/create_package\n",
            "  Switched to a new branch 'mjberry/create_package'\n",
            "  Branch 'mjberry/create_package' set up to track remote branch 'mjberry/create_package' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): kndatacleanup==0.1.24 from git+https://github.com/KnowEnG/Data_Cleanup_Pipeline.git@mjberry/create_package in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: kndatacleanup\n",
            "  Building wheel for kndatacleanup (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kndatacleanup: filename=kndatacleanup-0.1.24-cp36-none-any.whl size=21139 sha256=62af2702b0419b67114e0c10d2bcf46213578ebdaf734c8353bcb62449466c8c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rqk1jj16/wheels/f3/08/5f/bef0910710b5daac6a29ae5ea34600c52c0457457cb9f4b010\n",
            "Successfully built kndatacleanup\n",
            "Collecting git+https://github.com/KnowEnG/General_Clustering_Pipeline.git@mjberry/create_package\n",
            "  Cloning https://github.com/KnowEnG/General_Clustering_Pipeline.git (to revision mjberry/create_package) to /tmp/pip-req-build-m9pyz7s_\n",
            "  Running command git clone -q https://github.com/KnowEnG/General_Clustering_Pipeline.git /tmp/pip-req-build-m9pyz7s_\n",
            "  Running command git checkout -b mjberry/create_package --track origin/mjberry/create_package\n",
            "  Switched to a new branch 'mjberry/create_package'\n",
            "  Branch 'mjberry/create_package' set up to track remote branch 'mjberry/create_package' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): kngeneralclustering==0.1.24 from git+https://github.com/KnowEnG/General_Clustering_Pipeline.git@mjberry/create_package in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: kngeneralclustering\n",
            "  Building wheel for kngeneralclustering (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kngeneralclustering: filename=kngeneralclustering-0.1.24-cp36-none-any.whl size=10199 sha256=93ef819fef0f4c8c67b1f85eb85883a629eca3f03cf804e819f6fc93936a06de\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-s98k1vzq/wheels/82/14/fd/bbb4f8b52ee93f81fb3a0fd0d84aa0e0d32284aa8e2b794e76\n",
            "Successfully built kngeneralclustering\n",
            "Collecting git+https://github.com/KnowEnG/Samples_Clustering_Pipeline.git@mjberry/create_package\n",
            "  Cloning https://github.com/KnowEnG/Samples_Clustering_Pipeline.git (to revision mjberry/create_package) to /tmp/pip-req-build-66kr0e0p\n",
            "  Running command git clone -q https://github.com/KnowEnG/Samples_Clustering_Pipeline.git /tmp/pip-req-build-66kr0e0p\n",
            "  Running command git checkout -b mjberry/create_package --track origin/mjberry/create_package\n",
            "  Switched to a new branch 'mjberry/create_package'\n",
            "  Branch 'mjberry/create_package' set up to track remote branch 'mjberry/create_package' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): knsamplesclustering==0.1.24 from git+https://github.com/KnowEnG/Samples_Clustering_Pipeline.git@mjberry/create_package in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: knsamplesclustering\n",
            "  Building wheel for knsamplesclustering (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for knsamplesclustering: filename=knsamplesclustering-0.1.24-cp36-none-any.whl size=10306 sha256=ba657925bb9f5ed974649ca642dd86949d538b659d89d32538d0809da9278b3a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uuumi4wh/wheels/c4/9d/6e/142001d49f00deb23c6e1024de10a7941d8ed95c41f34e538b\n",
            "Successfully built knsamplesclustering\n",
            "Collecting git+https://github.com/KnowEnG/Feature_Prioritization_Pipeline.git@mjberry/create_package\n",
            "  Cloning https://github.com/KnowEnG/Feature_Prioritization_Pipeline.git (to revision mjberry/create_package) to /tmp/pip-req-build-atfp06rs\n",
            "  Running command git clone -q https://github.com/KnowEnG/Feature_Prioritization_Pipeline.git /tmp/pip-req-build-atfp06rs\n",
            "  Running command git checkout -b mjberry/create_package --track origin/mjberry/create_package\n",
            "  Switched to a new branch 'mjberry/create_package'\n",
            "  Branch 'mjberry/create_package' set up to track remote branch 'mjberry/create_package' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): knfeatureprioritization==0.1.24 from git+https://github.com/KnowEnG/Feature_Prioritization_Pipeline.git@mjberry/create_package in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: knfeatureprioritization\n",
            "  Building wheel for knfeatureprioritization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for knfeatureprioritization: filename=knfeatureprioritization-0.1.24-cp36-none-any.whl size=9532 sha256=c179ae983f5ada5875672499c0e6136b14cd527a9dadb9bc4e2a71cb698da6cc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rh30jmbl/wheels/9e/d2/d4/f01da17cddd382a7feba9fc395c395726466f119441ad44c3a\n",
            "Successfully built knfeatureprioritization\n",
            "Collecting git+https://github.com/KnowEnG/Gene_Prioritization_Pipeline.git@mjberry/create_package\n",
            "  Cloning https://github.com/KnowEnG/Gene_Prioritization_Pipeline.git (to revision mjberry/create_package) to /tmp/pip-req-build-r63utmbb\n",
            "  Running command git clone -q https://github.com/KnowEnG/Gene_Prioritization_Pipeline.git /tmp/pip-req-build-r63utmbb\n",
            "  Running command git checkout -b mjberry/create_package --track origin/mjberry/create_package\n",
            "  Switched to a new branch 'mjberry/create_package'\n",
            "  Branch 'mjberry/create_package' set up to track remote branch 'mjberry/create_package' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): kngeneprioritization==0.1.24 from git+https://github.com/KnowEnG/Gene_Prioritization_Pipeline.git@mjberry/create_package in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: kngeneprioritization\n",
            "  Building wheel for kngeneprioritization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kngeneprioritization: filename=kngeneprioritization-0.1.24-cp36-none-any.whl size=8669 sha256=93800a168984814d5cceba935b4a34a1ede400a16b63bd5a4beeb0e3a149d8b4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ftaf112_/wheels/43/81/4a/aa00410bb14cb46d36d646124b48aeee4214f6ec86fdcf553c\n",
            "Successfully built kngeneprioritization\n",
            "Collecting git+https://github.com/KnowEnG/Geneset_Characterization_Pipeline.git@mjberry/create_package\n",
            "  Cloning https://github.com/KnowEnG/Geneset_Characterization_Pipeline.git (to revision mjberry/create_package) to /tmp/pip-req-build-66uizb_2\n",
            "  Running command git clone -q https://github.com/KnowEnG/Geneset_Characterization_Pipeline.git /tmp/pip-req-build-66uizb_2\n",
            "  Running command git checkout -b mjberry/create_package --track origin/mjberry/create_package\n",
            "  Switched to a new branch 'mjberry/create_package'\n",
            "  Branch 'mjberry/create_package' set up to track remote branch 'mjberry/create_package' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): kngenesetcharacterization==0.1.24 from git+https://github.com/KnowEnG/Geneset_Characterization_Pipeline.git@mjberry/create_package in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: kngenesetcharacterization\n",
            "  Building wheel for kngenesetcharacterization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kngenesetcharacterization: filename=kngenesetcharacterization-0.1.24-cp36-none-any.whl size=9119 sha256=c858a049b930f84c89f26133b44927ca64a5ab95834bd2ce220f137a1c3a3c74\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sjc1nhj1/wheels/94/a3/3c/32ab0c5021ca5e3a783032f1066934c00bd22858721689a878\n",
            "Successfully built kngenesetcharacterization\n",
            "Collecting git+https://github.com/KnowEnG/Spreadsheets_Transformation.git@mjberry/create_package\n",
            "  Cloning https://github.com/KnowEnG/Spreadsheets_Transformation.git (to revision mjberry/create_package) to /tmp/pip-req-build-dm3fii_k\n",
            "  Running command git clone -q https://github.com/KnowEnG/Spreadsheets_Transformation.git /tmp/pip-req-build-dm3fii_k\n",
            "  Running command git checkout -b mjberry/create_package --track origin/mjberry/create_package\n",
            "  Switched to a new branch 'mjberry/create_package'\n",
            "  Branch 'mjberry/create_package' set up to track remote branch 'mjberry/create_package' from 'origin'.\n",
            "Requirement already satisfied (use --upgrade to upgrade): knspreadsheetstransformation==0.1.27 from git+https://github.com/KnowEnG/Spreadsheets_Transformation.git@mjberry/create_package in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: knspreadsheetstransformation\n",
            "  Building wheel for knspreadsheetstransformation (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for knspreadsheetstransformation: filename=knspreadsheetstransformation-0.1.27-cp36-none-any.whl size=15301 sha256=2f53e5a6cbccb6e9daef24adb017fd5a8beeed2725ff1f9e4d8ed0dafb9e11a9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k6uo6g_u/wheels/b1/f4/2f/2624ac2197f0da315de8c9fc4668ee50b86e717de75b3416c4\n",
            "Successfully built knspreadsheetstransformation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftgYqoTDuzOu",
        "colab_type": "text"
      },
      "source": [
        "## Environment Setup\n",
        "\n",
        "The cell below sets up the environment for running the analyses. Run the cell and wait for it to complete. You won't see any text output this time.\n",
        "\n",
        "You probably will not need to call any of the methods defined in this method, and you probably will not need to edit anything in the cell.\n",
        "\n",
        "You **will** need to re-run the cell whenever your notebook connects to a new virtual machine.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ifxh2nzm173",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import os\n",
        "import shutil\n",
        "from tempfile import mkdtemp\n",
        "import urllib.request\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "from kndatacleanup import data_cleanup\n",
        "from knfeatureprioritization import feature_prioritization\n",
        "from kngeneprioritization import gene_prioritization\n",
        "from kngenesetcharacterization import geneset_characterization\n",
        "from knsamplesclustering import samples_clustering\n",
        "from kngeneralclustering import general_clustering\n",
        "from knspreadsheetstransformation.spreadsheets_transformation_toolbox import \\\n",
        "    get_cluster_binary_dataframe\n",
        "\n",
        "NETWORK_DIR_PATH = '/network/'\n",
        "\n",
        "REDIS_PARAMS = {\n",
        "    'host': 'knowredis.knoweng.org',\n",
        "    'password': 'KnowEnG',\n",
        "    'port': 6379\n",
        "}\n",
        "\n",
        "NUM_CPUS = 2\n",
        "\n",
        "def fetch_network(edge_file_path):\n",
        "    \"\"\"TODO\"\"\"\n",
        "    if not os.path.isfile(edge_file_path):\n",
        "        url = \"https://s3.amazonaws.com/KnowNets/KN-20rep-1706/\" + \\\n",
        "            \"userKN-20rep-1706/\" + edge_file_path[len(NETWORK_DIR_PATH):]\n",
        "        os.makedirs(os.path.dirname(edge_file_path), exist_ok=True)\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            with open(edge_file_path, 'wb') as out_file:\n",
        "                shutil.copyfileobj(response, out_file)\n",
        "\n",
        "def fetch_network_metadata():\n",
        "    filenames = ['db_contents.txt', 'species_desc.txt', 'edge_type.txt']\n",
        "    for filename in filenames:\n",
        "        out_file_path = os.path.join(NETWORK_DIR_PATH, filename)\n",
        "        if not os.path.isfile(out_file_path):\n",
        "            url = \"https://s3.amazonaws.com/KnowNets/KN-20rep-1706/\" + \\\n",
        "                \"userKN-20rep-1706/\" + filename\n",
        "            with urllib.request.urlopen(url) as response:\n",
        "                with open(out_file_path, 'wb') as out_file:\n",
        "                    shutil.copyfileobj(response, out_file)\n",
        "\n",
        "def get_path_to_newest_file_having_prefix(search_dir_path, prefix):\n",
        "    \"\"\"TODO\"\"\"\n",
        "    matches = [os.path.join(search_dir_path, name) for name \\\n",
        "        in os.listdir(search_dir_path) if name.startswith(prefix)]\n",
        "    if matches:\n",
        "        return sorted(matches, key=lambda path: os.path.getctime(path), reverse=True)[0]\n",
        "    else:\n",
        "        raise Exception(\"No file found with prefix \" + prefix + \" in \" + \\\n",
        "            search_dir_path + \".\")\n",
        "\n",
        "def get_cleaned_file_path(original_file_path, results_dir_path):\n",
        "    \"\"\"TODO\"\"\"\n",
        "    original_name = os.path.basename(original_file_path)\n",
        "    original_name_root = os.path.splitext(original_name)[0]\n",
        "    return os.path.join(results_dir_path, original_name_root + \"_ETL.tsv\")\n",
        "\n",
        "def get_gene_map_file_path(original_file_path, results_dir_path):\n",
        "    \"\"\"TODO\"\"\"\n",
        "    original_name = os.path.basename(original_file_path)\n",
        "    original_name_root = os.path.splitext(original_name)[0]\n",
        "    return os.path.join(results_dir_path, original_name_root + \"_MAP.tsv\")\n",
        "\n",
        "os.makedirs(NETWORK_DIR_PATH, exist_ok=True)\n",
        "fetch_network_metadata()\n",
        "\n",
        "!rm -rf /content/sample_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4DCoKLVwBvT",
        "colab_type": "text"
      },
      "source": [
        "## Knowledge Network Utility Methods\n",
        "\n",
        "The cell below defines several utility methods for working with the knowledge network. These methods are used in the example analyses and might be useful to you in your project. Run the cell and wait for it to complete. It won't produce any text output.\n",
        "\n",
        "You probably will not need to edit anything within the cell.\n",
        "\n",
        "A later cell shows how to use the knowledge network utility methods.\n",
        "\n",
        "You **will** need to re-run the cell whenever your notebook connects to a new virtual machine.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKn3Uxx6rLce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_network_species():\n",
        "    \"\"\"TODO\"\"\"\n",
        "    return_val = []\n",
        "    species_file_path = os.path.join(NETWORK_DIR_PATH, 'species_desc.txt')\n",
        "    with open(species_file_path) as csvfile:\n",
        "        for row in csv.reader(csvfile, delimiter='\\t'):\n",
        "            return_val.append({\n",
        "                'id': row[0],\n",
        "                'short_latin_name': row[1],\n",
        "                'latin_name': row[2],\n",
        "                'familiar_name': row[3],\n",
        "                'group_name': row[5]\n",
        "            })\n",
        "    return return_val\n",
        "\n",
        "def display_network_species():\n",
        "    \"\"\"TODO\"\"\"\n",
        "    html_string = \"<table><tr><th>Familiar Name (Latin Name)</th><th>Species Id</th></tr>\"\n",
        "    for species in get_network_species():\n",
        "        html_string += \"<tr><td>\" + species['familiar_name'] + \" (\" + \\\n",
        "            species['latin_name'] + \")</td><td>\" + species['id'] + \"</td></tr>\"\n",
        "    html_string += \"</table>\"\n",
        "    return HTML(html_string)\n",
        "\n",
        "def get_edge_type_name_to_pretty_name():\n",
        "    \"\"\"TODO\"\"\"\n",
        "    return_val = {}\n",
        "    file_path = os.path.join(NETWORK_DIR_PATH, 'edge_type.txt')\n",
        "    with open(file_path) as csvfile:\n",
        "        for row in csv.DictReader(csvfile, delimiter='\\t'):\n",
        "            return_val[row['et_name']] = row['pretty_name']\n",
        "    return return_val\n",
        "\n",
        "def get_interaction_networks(species_id):\n",
        "    \"\"\"TODO\"\"\"\n",
        "    species_id = str(species_id) # user-friendliness\n",
        "    return_val = []\n",
        "    contents_file_path = os.path.join(NETWORK_DIR_PATH, 'db_contents.txt')\n",
        "    with open(contents_file_path) as csvfile:\n",
        "        edge_type_name_to_pretty_name = get_edge_type_name_to_pretty_name()\n",
        "        for row in csv.DictReader(csvfile, delimiter='\\t'):\n",
        "            if row['n1_type'] == 'Gene' and row['taxon'] == species_id:\n",
        "                return_val.append({\n",
        "                    'name': edge_type_name_to_pretty_name[row['et_name']],\n",
        "                    'edge_file_path': os.path.join(\\\n",
        "                        NETWORK_DIR_PATH, 'Gene', species_id, row['et_name'], \\\n",
        "                        species_id + '.' + row['et_name'] + '.edge')\n",
        "                })\n",
        "    return return_val\n",
        "\n",
        "def display_interaction_networks(species_id):\n",
        "    \"\"\"TODO\"\"\"\n",
        "    html_string = \"<table><tr><th>Interaction Network Name</th><th>Edge File Path</th></tr>\"\n",
        "    for network in get_interaction_networks(species_id):\n",
        "        html_string += \"<tr><td>\" + network['name'] + \"</td><td>\" + \\\n",
        "            network['edge_file_path'] + \"</td></tr>\"\n",
        "    html_string += \"</table>\"\n",
        "    return HTML(html_string)\n",
        "\n",
        "def get_gene_property_networks(species_id):\n",
        "    \"\"\"TODO\"\"\"\n",
        "    species_id = str(species_id) # user-friendliness\n",
        "    return_val = []\n",
        "    contents_file_path = os.path.join(NETWORK_DIR_PATH, 'db_contents.txt')\n",
        "    with open(contents_file_path) as csvfile:\n",
        "        edge_type_name_to_pretty_name = get_edge_type_name_to_pretty_name()\n",
        "        for row in csv.DictReader(csvfile, delimiter='\\t'):\n",
        "            if row['n1_type'] == 'Property' and row['taxon'] == species_id:\n",
        "                return_val.append({\n",
        "                    'name': edge_type_name_to_pretty_name[row['et_name']],\n",
        "                    'edge_file_path': os.path.join(\\\n",
        "                        NETWORK_DIR_PATH, 'Property', species_id, row['et_name'], \\\n",
        "                        species_id + '.' + row['et_name'] + '.edge')\n",
        "                })\n",
        "    return return_val\n",
        "\n",
        "def display_gene_property_networks(species_id):\n",
        "    \"\"\"TODO\"\"\"\n",
        "    html_string = \"<table><tr><th>Interaction Network Name</th><th>Edge File Path</th></tr>\"\n",
        "    for network in get_gene_property_networks(species_id):\n",
        "        html_string += \"<tr><td>\" + network['name'] + \"</td><td>\" + \\\n",
        "            network['edge_file_path'] + \"</td></tr>\"\n",
        "    html_string += \"</table>\"\n",
        "    return HTML(html_string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVvYGbnRxE-9",
        "colab_type": "text"
      },
      "source": [
        "### Using the Knowledge Network Utility Methods\n",
        "\n",
        "The three cells below show how `display_network_species`, `display_interaction_networks`, and `display_gene_property_networks` can be called to view information about the knowledge network. This information can be useful in configuring analyses, as you'll see later.\n",
        "\n",
        "These methods are based on three other methods defined in the cell above, `get_network_species`, `get_interaction_networks`, and `get_gene_property_networks`. The \"get\" versions return the same information as the \"display\" versions, but the \"get\" versions return it in a format convenient for use in code instead of a format that's easy to read.\n",
        "\n",
        "You **will not** need to re-run these three cells whenever your notebook connects to a new virtual machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSMHjVi6tnNc",
        "colab_type": "code",
        "outputId": "8463a497-55d9-412a-abe8-181d0d589dd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "source": [
        "# display all species in the knowledge network\n",
        "display_network_species()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table><tr><th>Familiar Name (Latin Name)</th><th>Species Id</th></tr><tr><td>Human (Homo sapiens)</td><td>9606</td></tr><tr><td>Chimpanzee (Pan troglodytes)</td><td>9598</td></tr><tr><td>Cow (Bos taurus)</td><td>9913</td></tr><tr><td>Dog (Canis familiaris)</td><td>9615</td></tr><tr><td>Macaque (Macaca mulatta)</td><td>9544</td></tr><tr><td>Mouse (Mus musculus)</td><td>10090</td></tr><tr><td>Pig (Sus scrofa)</td><td>9823</td></tr><tr><td>Rat (Rattus norvegicus)</td><td>10116</td></tr><tr><td>Chicken (Gallus gallus)</td><td>9031</td></tr><tr><td>Clawed frog (Xenopus tropicalis)</td><td>8364</td></tr><tr><td>Stickleback (Gasterosteus aculeatus)</td><td>69293</td></tr><tr><td>Zebra finch (Taeniopygia guttata)</td><td>59729</td></tr><tr><td>Zebrafish (Danio rerio)</td><td>7955</td></tr><tr><td>Fruitfly (Drosophila melanogaster)</td><td>7227</td></tr><tr><td>Honey bee (Apis mellifera)</td><td>7460</td></tr><tr><td>Mosquito (Aedes aegypti)</td><td>7159</td></tr><tr><td>Roundworm (Caenorhabditis elegans)</td><td>6239</td></tr><tr><td>Thale cress (Arabidopsis thaliana)</td><td>3702</td></tr><tr><td>Water flea (Daphnia pulex)</td><td>6669</td></tr><tr><td>Yeast (Saccharomyces cerevisiae)</td><td>4932</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uep6yYfe83ly",
        "colab_type": "code",
        "outputId": "6a0e38e2-0557-41f0-ce3c-70f6cb02c983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        }
      },
      "source": [
        "# display interaction networks for rat (species id 10116)\n",
        "display_interaction_networks('10116')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table><tr><th>Interaction Network Name</th><th>Edge File Path</th></tr><tr><td>Blastp Protein Sequence Similarity</td><td>/network/Gene/10116/blastp_homology/10116.blastp_homology.edge</td></tr><tr><td>Pathway Commons Catalysis Precedes</td><td>/network/Gene/10116/pathcom_catalysis_precedes/10116.pathcom_catalysis_precedes.edge</td></tr><tr><td>Pathway Commons Controls Expression</td><td>/network/Gene/10116/pathcom_controls_expression_of/10116.pathcom_controls_expression_of.edge</td></tr><tr><td>Pathway Commons Controls Phosphorylation</td><td>/network/Gene/10116/pathcom_controls_phosphorylation_of/10116.pathcom_controls_phosphorylation_of.edge</td></tr><tr><td>Pathway Commons Controls State Change</td><td>/network/Gene/10116/pathcom_controls_state_change_of/10116.pathcom_controls_state_change_of.edge</td></tr><tr><td>Pathway Commons In Complex With</td><td>/network/Gene/10116/pathcom_in_complex_with/10116.pathcom_in_complex_with.edge</td></tr><tr><td>PPI Protein Complex Association</td><td>/network/Gene/10116/PPI_association/10116.PPI_association.edge</td></tr><tr><td>PPI Colocalization</td><td>/network/Gene/10116/PPI_colocalization/10116.PPI_colocalization.edge</td></tr><tr><td>PPI Direct Interaction</td><td>/network/Gene/10116/PPI_direct_interaction/10116.PPI_direct_interaction.edge</td></tr><tr><td>PPI Genetic Interaction</td><td>/network/Gene/10116/PPI_genetic_interaction/10116.PPI_genetic_interaction.edge</td></tr><tr><td>PPI Physical Association</td><td>/network/Gene/10116/PPI_physical_association/10116.PPI_physical_association.edge</td></tr><tr><td>Reactome PPI Direct Complex</td><td>/network/Gene/10116/reactome_PPI_direct_complex/10116.reactome_PPI_direct_complex.edge</td></tr><tr><td>Reactome PPI Indirect Complex</td><td>/network/Gene/10116/reactome_PPI_indirect_complex/10116.reactome_PPI_indirect_complex.edge</td></tr><tr><td>Reactome PPI Reaction Partners</td><td>/network/Gene/10116/reactome_PPI_reaction/10116.reactome_PPI_reaction.edge</td></tr><tr><td>STRING Co-expression</td><td>/network/Gene/10116/STRING_coexpression/10116.STRING_coexpression.edge</td></tr><tr><td>STRING Functional Databases</td><td>/network/Gene/10116/STRING_database/10116.STRING_database.edge</td></tr><tr><td>STRING Experimental PPI</td><td>/network/Gene/10116/STRING_experimental/10116.STRING_experimental.edge</td></tr><tr><td>STRING Gene Fusion Event</td><td>/network/Gene/10116/STRING_fusion/10116.STRING_fusion.edge</td></tr><tr><td>STRING Proximal Neighborhood</td><td>/network/Gene/10116/STRING_neighborhood/10116.STRING_neighborhood.edge</td></tr><tr><td>STRING Text Mining from Abstracts</td><td>/network/Gene/10116/STRING_textmining/10116.STRING_textmining.edge</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNl8XB-T84x5",
        "colab_type": "code",
        "outputId": "737d5e7c-aa80-49db-8157-d38ee0be4846",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# display gene property networks for roundworm (species id 6239)\n",
        "display_gene_property_networks('6239')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table><tr><th>Interaction Network Name</th><th>Edge File Path</th></tr><tr><td>Gene Ontology</td><td>/network/Property/6239/gene_ontology/6239.gene_ontology.edge</td></tr><tr><td>Pathway Commons Pathways</td><td>/network/Property/6239/pathcom_pathway/6239.pathcom_pathway.edge</td></tr><tr><td>PFam Prot Domains</td><td>/network/Property/6239/pfam_prot/6239.pfam_prot.edge</td></tr><tr><td>Reactome Pathways Curated</td><td>/network/Property/6239/reactome_annotation/6239.reactome_annotation.edge</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmTUV9Lp_rK0",
        "colab_type": "text"
      },
      "source": [
        "## Analytics Methods\n",
        "\n",
        "The cell below defines methods for running clustering, prioritization, and gene-set characterization. Run the cell and wait for it to complete. It won't produce any output.\n",
        "\n",
        "You **will** need to re-run the cell whenever your notebook connects to a new virtual machine.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M6MGR3K_pd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def do_clustering(\\\n",
        "    omics_file_path, phenotype_file_path, results_dir_path, num_clusters, \\\n",
        "    species_id, interaction_network_edge_file_path, network_influence, \\\n",
        "    num_bootstraps, bootstrap_sample_fraction):\n",
        "    \"\"\"TODO\"\"\"\n",
        "    species_id = str(species_id) # user-friendliness\n",
        "    os.makedirs(results_dir_path, exist_ok=True)\n",
        "\n",
        "    if interaction_network_edge_file_path is None:\n",
        "        pipeline_type = 'general_clustering_pipeline'\n",
        "    else:\n",
        "        fetch_network(interaction_network_edge_file_path)\n",
        "        pipeline_type = 'samples_clustering_pipeline'\n",
        "\n",
        "    cleanup_parameters = {\n",
        "        'spreadsheet_name_full_path': omics_file_path,\n",
        "        'pipeline_type': pipeline_type,\n",
        "        'results_directory': results_dir_path\n",
        "    }\n",
        "    if phenotype_file_path is not None:\n",
        "        cleanup_parameters['phenotype_name_full_path'] = phenotype_file_path\n",
        "    if interaction_network_edge_file_path is not None:\n",
        "        cleanup_parameters.update({\n",
        "            'gg_network_name_full_path': interaction_network_edge_file_path,\n",
        "            'taxonid': species_id,\n",
        "            'source_hint': '',\n",
        "            'redis_credential': {\n",
        "                'host': REDIS_PARAMS['host'],\n",
        "                'port': REDIS_PARAMS['port'],\n",
        "                'password': REDIS_PARAMS['password']\n",
        "            }\n",
        "        })\n",
        "    data_cleanup.run_pipelines(cleanup_parameters, data_cleanup.SELECT[pipeline_type])\n",
        "\n",
        "    clustering_parameters = {\n",
        "        'spreadsheet_name_full_path': get_cleaned_file_path(omics_file_path, results_dir_path),\n",
        "        'results_directory': results_dir_path,\n",
        "        'processing_method': 'parallel',\n",
        "        'parallelism': NUM_CPUS,\n",
        "        'number_of_clusters': num_clusters,\n",
        "        'run_directory': results_dir_path,\n",
        "        'tmp_directory': './tmp'\n",
        "    }\n",
        "    if phenotype_file_path is not None:\n",
        "        clustering_parameters.update({\n",
        "            'phenotype_name_full_path': get_cleaned_file_path(phenotype_file_path, results_dir_path),\n",
        "            'threshold': 15\n",
        "        })\n",
        "\n",
        "    method_prefix = ''\n",
        "    if num_bootstraps > 0:\n",
        "        clustering_parameters.update({\n",
        "            'number_of_bootstraps': num_bootstraps,\n",
        "            'rows_sampling_fraction': 1.0,\n",
        "            'cols_sampling_fraction': bootstrap_sample_fraction\n",
        "        })\n",
        "        method_prefix = 'cc_'\n",
        "\n",
        "    if interaction_network_edge_file_path is not None:\n",
        "        clustering_parameters.update({\n",
        "            'gg_network_name_full_path': interaction_network_edge_file_path,\n",
        "            'rwr_max_iterations': 100,\n",
        "            'rwr_convergence_tolerence': 1.0e-4,\n",
        "            'rwr_restart_probability': network_influence,\n",
        "            'top_number_of_genes': 100,\n",
        "            'nmf_conv_check_freq': 50,\n",
        "            'nmf_max_invariance': 200,\n",
        "            'nmf_max_iterations': 10000,\n",
        "            'nmf_penalty_parameter': 1400,\n",
        "            'method': method_prefix + 'net_nmf'\n",
        "        })\n",
        "        samples_clustering.SELECT[clustering_parameters['method']](clustering_parameters)\n",
        "    else:\n",
        "        clustering_parameters.update({\n",
        "            'top_number_of_rows': 100,\n",
        "            'affinity_metric': 'euclidean',\n",
        "            'linkage_criterion': 'ward',\n",
        "            'method': method_prefix + 'hclust'\n",
        "        })\n",
        "        general_clustering.SELECT[clustering_parameters['method']](clustering_parameters)\n",
        "\n",
        "def do_prioritization(\\\n",
        "    omics_file_path, phenotype_file_path, results_dir_path, \\\n",
        "    correlation_measure, missing_value_strategy, num_exported_features, \\\n",
        "    num_response_correlated_features, species_id, \\\n",
        "    interaction_network_edge_file_path, network_influence):\n",
        "    \"\"\"TODO\"\"\"\n",
        "    species_id = str(species_id) # user-friendliness\n",
        "    os.makedirs(results_dir_path, exist_ok=True)\n",
        "\n",
        "    if interaction_network_edge_file_path is None:\n",
        "        pipeline_type = 'feature_prioritization_pipeline'\n",
        "    else:\n",
        "        fetch_network(interaction_network_edge_file_path)\n",
        "        pipeline_type = 'gene_prioritization_pipeline'\n",
        "\n",
        "    cleanup_parameters = {\n",
        "        'spreadsheet_name_full_path': omics_file_path,\n",
        "        'phenotype_name_full_path': phenotype_file_path,\n",
        "        'pipeline_type': pipeline_type,\n",
        "        'correlation_measure': correlation_measure, # t_test, pearson, edgeR\n",
        "        'impute': missing_value_strategy, # average, remove, reject\n",
        "        'results_directory': results_dir_path\n",
        "    }\n",
        "    if interaction_network_edge_file_path is not None:\n",
        "        cleanup_parameters.update({\n",
        "            'taxonid': species_id,\n",
        "            'source_hint': '',\n",
        "            'redis_credential': {\n",
        "                    'host': REDIS_PARAMS['host'],\n",
        "                    'port': REDIS_PARAMS['port'],\n",
        "                    'password': REDIS_PARAMS['password']\n",
        "            }\n",
        "        })\n",
        "    data_cleanup.run_pipelines(cleanup_parameters, data_cleanup.SELECT[pipeline_type])\n",
        "\n",
        "    prioritization_parameters = {\n",
        "        'correlation_measure': correlation_measure,\n",
        "        'spreadsheet_name_full_path': get_cleaned_file_path(omics_file_path, results_dir_path),\n",
        "        'phenotype_name_full_path': get_cleaned_file_path(phenotype_file_path, results_dir_path),\n",
        "        'results_directory': results_dir_path,\n",
        "        'top_gamma_of_sort': num_exported_features,\n",
        "        'max_cpu': NUM_CPUS\n",
        "    }\n",
        "    if interaction_network_edge_file_path is not None:\n",
        "        prioritization_parameters.update({\n",
        "            'gg_network_name_full_path': interaction_network_edge_file_path,\n",
        "            'rwr_max_iterations': 100,\n",
        "            'rwr_convergence_tolerence': 1.0e-4,\n",
        "            'rwr_restart_probability': network_influence,\n",
        "            'top_beta_of_sort': num_response_correlated_features,\n",
        "            'method': 'net_correlation'\n",
        "        })\n",
        "        gene_prioritization.net_correlation(prioritization_parameters)\n",
        "    else:\n",
        "        prioritization_parameters.update({\n",
        "            'top_beta_of_sort': num_exported_features,\n",
        "            'method': 'correlation',\n",
        "        })\n",
        "        feature_prioritization.correlation(prioritization_parameters)\n",
        "\n",
        "def do_characterization(\\\n",
        "    gene_matrix_file_path, results_dir_path, species_id, \\\n",
        "    gene_property_edge_file_path, interaction_network_edge_file_path, \\\n",
        "    network_influence):\n",
        "    \"\"\"TODO\"\"\"\n",
        "    species_id = str(species_id) # user-friendliness\n",
        "    os.makedirs(results_dir_path, exist_ok=True)\n",
        "\n",
        "    fetch_network(gene_property_edge_file_path)\n",
        "\n",
        "    cleanup_parameters = {\n",
        "        'spreadsheet_name_full_path': gene_matrix_file_path,\n",
        "        'pipeline_type': 'geneset_characterization_pipeline',\n",
        "        'results_directory': results_dir_path,\n",
        "        'taxonid': species_id,\n",
        "        'source_hint': '',\n",
        "        'redis_credential': {\n",
        "            'host': REDIS_PARAMS['host'],\n",
        "            'port': REDIS_PARAMS['port'],\n",
        "            'password': REDIS_PARAMS['password']\n",
        "        }\n",
        "    }\n",
        "    data_cleanup.run_pipelines(cleanup_parameters, data_cleanup.SELECT[pipeline_type])\n",
        "\n",
        "    characterization_parameters = {\n",
        "        'spreadsheet_name_full_path': get_cleaned_file_path(gene_matrix_file_path, results_dir_path),\n",
        "        'gene_names_map': get_gene_map_path(gene_matrix_file_path, results_dir_path),\n",
        "        'results_directory': results_dir_path,\n",
        "        'pg_network_name_full_path': gene_property_edge_file_path,\n",
        "        'max_cpu': NUM_CPUS\n",
        "    }\n",
        "    if interaction_network_edge_file_path is None:\n",
        "        characterization_parameters.update({\n",
        "            'method': 'fisher'\n",
        "        })\n",
        "        geneset_characterization.fisher(characterization_parameters)\n",
        "    else:\n",
        "        fetch_network(interaction_network_edge_file_path)\n",
        "        characterization_parameters.update({\n",
        "            'method': 'DRaWR',\n",
        "            'rwr_max_iterations': 500,\n",
        "            'rwr_convergence_tolerence': 1.0e-4,\n",
        "            'rwr_restart_probability': network_influence,\n",
        "            'gg_network_name_full_path': interaction_network_edge_file_path\n",
        "        })\n",
        "        geneset_characterization.DRaWR(characterization_parameters)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRxFpjpTM0b8",
        "colab_type": "text"
      },
      "source": [
        "## Connect to Google Drive\n",
        "\n",
        "The cell below enables this notebook to use your Google Drive for file storage. Subsequent cells will use this access to load the example files you copied earlier and to save results of the example analyses. You might also find this helpful in running your own analyses.\n",
        "\n",
        "Run the cell and click on the link that appears in the output. On the linked page, select your illinois.edu account and grant the requested permissions. The page will then display a code. Copy the code and paste it in the box that appears in the output below. Then press Enter.\n",
        "\n",
        "You **will** need to re-run the cell whenever your notebook connects to a new virtual machine.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTqz9ZNXvlG_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "360d3982-5945-43b2-cb90-99c7b20cb3af"
      },
      "source": [
        "from google.colab import drive\n",
        "GDRIVE_MOUNT_PATH = '/content/gdrive'\n",
        "drive.mount(GDRIVE_MOUNT_PATH)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC9dFiPKnLmv",
        "colab_type": "text"
      },
      "source": [
        "## Setting File Locations\n",
        "\n",
        "In the cell below, we will tell the notebook where the example files can be found and where the results should be saved.\n",
        "\n",
        "To confirm the location, find the arrow symbol (>) near the top left corner of the portion of your screen that shows the notebook content. Click it to reveal a panel with three tabs labeled `Table of contents`, `Code snippets`, and `Files`. Click on the `Files` tab.\n",
        "\n",
        "In the `Files` tab, you should see one folder named `gdrive`. Click the arrow next to the `gdrive` folder to expand it, and continue navigating through the folders until you find the `example_analyses` folder copied previously. Right-click on `example_analyses` and select `Copy path`. Paste the value into the cell below, and compare it to the value assigned to `INPUT_DATA_DIR_PATH`. If the values are different, replace the pre-coded value with the one you pasted. Once you have done that, run the cell.\n",
        "\n",
        "If at any point you open the `Files` tab or click its `REFRESH` button and do not see `gdrive`, you might need to re-run the previous cell.\n",
        "\n",
        "Note this cell also specifies the output directories that will be used for the different analyses in the example. They are defined here, in the last quick-running cell before the analyses below, because the variables will need to be refreshed if your notebook connects to a new virtual machine.\n",
        "\n",
        "You **will** need to re-run the cell whenever your notebook connects to a new virtual machine, but the value assigned to `INPUT_DATA_DIR_PATH` will not change unless you move the folder within your Google Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnBOrd8rMm2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DATA_DIR_PATH = '/content/gdrive/My Drive/College of Medicine Data Science Project/Genomics/example_analyses'\n",
        "OUTPUT_DATA_DIR_PATH = os.path.join(INPUT_DATA_DIR_PATH, 'results')\n",
        "\n",
        "CLUSTERING1_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'clustering1')\n",
        "CLUSTERING2_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'clustering2')\n",
        "CLUSTERING3_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'clustering3')\n",
        "CLUSTERING4_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'clustering4')\n",
        "CLUSTERING5_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'clustering5')\n",
        "CLUSTERING6_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'clustering6')\n",
        "\n",
        "PRIORITIZATION1_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'prioritization1')\n",
        "PRIORITIZATION2_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'prioritization2')\n",
        "PRIORITIZATION3_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'prioritization3')\n",
        "\n",
        "CHARACTERIZATION1_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'characterization1')\n",
        "CHARACTERIZATION2_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'characterization2')\n",
        "CHARACTERIZATION3_DIR_PATH = os.path.join(OUTPUT_DATA_DIR_PATH, 'characterization3')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t-CbUY6sP2K",
        "colab_type": "text"
      },
      "source": [
        "## Clustering\n",
        "\n",
        "The following four cells will use standard clustering techniques to group samples according to different omics data. Run each cell; note each will take several minutes. You'll see some output describing the inputs and results.\n",
        "\n",
        "As each of these cells finishes, it will store the results to your Google Drive. For that reason, you **will not** need to re-run these cells whenever your notebook connects to a new virtual machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub32Jwwksg31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "do_clustering(\\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_clustering1_genecopynumber.tsv'), \\\n",
        "    None, CLUSTERING1_DIR_PATH, 8, None, None, None, 0, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKX0UCvmskVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "do_clustering(\\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_clustering2_exp_HiSeqV2.tsv'), \\\n",
        "    None, CLUSTERING2_DIR_PATH, 13, None, None, None, 0, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV7S9H7FsngW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "do_clustering(\\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_clustering3_hMethyl.tsv'), \\\n",
        "    None, CLUSTERING3_DIR_PATH, 19, None, None, None, 0, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFJcuLclspo5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "do_clustering(\\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_clustering4_RPPA_RBN.tsv'), \\\n",
        "    None, CLUSTERING4_DIR_PATH, 8, None, None, None, 0, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWMbtPJZssUT",
        "colab_type": "text"
      },
      "source": [
        "### Network-Based Clustering\n",
        "\n",
        "This fifth clustering analysis incorporates the knowledge network in order to improve results over sparse omics data. As with the above clustering analyses, run the cell and wait until it completes.\n",
        "\n",
        "As with all of the analysis cells, it will store the results to your Google Drive. For that reason, you **will not** need to re-run this cell whenever your notebook connects to a new virtual machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mnPXgrTss9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "do_clustering(\\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_clustering5_mutation.tsv'), \\\n",
        "    None, CLUSTERING5_DIR_PATH, 14, '9606', \\\n",
        "    '/network/Gene/9606/hn_IntNet/9606.hn_IntNet.edge', 0.5, 0, None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwpR_2p-bwjo",
        "colab_type": "text"
      },
      "source": [
        "### Cluster-of-Clusters Analysis (COCA)\n",
        "\n",
        "This sixth clustering analysis operates upon the cluster assignments generated by the previous five clustering analyses. Again, run the cell and wait until it finishes.\n",
        "\n",
        "As with all of the analysis cells, it will store the results to your Google Drive. For that reason, you **will not** need to re-run this cell whenever your notebook connects to a new virtual machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8Kdpf2McHdS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "outputId": "8d85429b-59f3-4bf9-ee61-e8861926561f"
      },
      "source": [
        "# gather the outputs from the five previous clustering analyses\n",
        "raw_coca_inputs = [\n",
        "    get_path_to_newest_file_having_prefix(CLUSTERING1_DIR_PATH, 'samples_label_by_cluster'),\n",
        "    get_path_to_newest_file_having_prefix(CLUSTERING2_DIR_PATH, 'samples_label_by_cluster'),\n",
        "    get_path_to_newest_file_having_prefix(CLUSTERING3_DIR_PATH, 'samples_label_by_cluster'),\n",
        "    get_path_to_newest_file_having_prefix(CLUSTERING4_DIR_PATH, 'samples_label_by_cluster'),\n",
        "    get_path_to_newest_file_having_prefix(CLUSTERING5_DIR_PATH, 'samples_label_by_cluster')\n",
        "]\n",
        "\n",
        "# assemble the raw inputs into a single file formatted like an omics file\n",
        "coca_input_file_path = os.path.join(CLUSTERING6_DIR_PATH, 'input.tsv')\n",
        "temp_dir_path = mkdtemp()\n",
        "for input in raw_coca_inputs:\n",
        "    shutil.copy(input, temp_dir_path)\n",
        "coca_input_df = get_cluster_binary_dataframe(\\\n",
        "    [os.path.basename(input) for input in raw_coca_inputs], temp_dir_path)\n",
        "coca_input_df.to_csv(coca_input_file_path, sep='\\t')\n",
        "shutil.rmtree(temp_dir_path)\n",
        "\n",
        "do_clustering(\\\n",
        "    coca_input_file_path, \\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_clustering_clinical_data.tsv'), \\\n",
        "    CLUSTERING6_DIR_PATH, 13, None, None, None, 200, 0.8)\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unexpected error during reading input file /content/gdrive/My Drive/College of Medicine Data Science Project/Genomics/example_analyses/results/clustering6/input_ETL.tsv: <class 'FileNotFoundError'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-1eb2e909cb07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_dir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdo_clustering\u001b[0m\u001b[0;34m(\u001b[0m    \u001b[0mcoca_input_file_path\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_DATA_DIR_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in_clustering_clinical_data.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0mCLUSTERING6_DIR_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-b9c55307880e>\u001b[0m in \u001b[0;36mdo_clustering\u001b[0;34m(omics_file_path, phenotype_file_path, results_dir_path, num_clusters, species_id, interaction_network_edge_file_path, network_influence, num_bootstraps, bootstrap_sample_fraction)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;34m'method'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmethod_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'hclust'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         })\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mgeneral_clustering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSELECT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclustering_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'method'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclustering_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdo_prioritization\u001b[0m\u001b[0;34m(\u001b[0m    \u001b[0momics_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphenotype_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_dir_path\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0mcorrelation_measure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_value_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_exported_features\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0mnum_response_correlated_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecies_id\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0minteraction_network_edge_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_influence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kngeneralclustering/general_clustering.py\u001b[0m in \u001b[0;36mcc_hclust\u001b[0;34m(run_parameters)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;34m\"\"\" consensus clustering hclust \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgeneral_clustering_toolbox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_cc_hclust\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mrun_cc_hclust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcc_link_hclust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kngeneralclustering/general_clustering_toolbox.py\u001b[0m in \u001b[0;36mrun_cc_hclust\u001b[0;34m(run_parameters)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mspreadsheet_name_full_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spreadsheet_name_full_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0mspreadsheet_df\u001b[0m             \u001b[0;34m=\u001b[0m \u001b[0mkn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_spreadsheet_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspreadsheet_name_full_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0mspreadsheet_mat\u001b[0m            \u001b[0;34m=\u001b[0m \u001b[0mspreadsheet_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mnumber_of_samples\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0mspreadsheet_mat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/knpackage/toolbox.py\u001b[0m in \u001b[0;36mget_spreadsheet_df\u001b[0;34m(spreadsheet_name_full_path)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mspreadsheet_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspreadsheet_name_full_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# casting index and columns to String type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/content/gdrive/My Drive/College of Medicine Data Science Project/Genomics/example_analyses/results/clustering6/input_ETL.tsv' does not exist: b'/content/gdrive/My Drive/College of Medicine Data Science Project/Genomics/example_analyses/results/clustering6/input_ETL.tsv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mRscDmTd9UF",
        "colab_type": "text"
      },
      "source": [
        "## Gene Prioritization\n",
        "\n",
        "The following three cells will analyze gene expression data to determine the genes most associated with phenotypes of interest.\n",
        "\n",
        "In the first of the three prioritization cells, the phenotypes are PANCAN disease types, and the method is a standard prioritization technique. Run the cell and wait until it finishes.\n",
        "\n",
        "As with all of the analysis cells, it will store the results to your Google Drive. For that reason, you **will not** need to re-run this cell whenever your notebook connects to a new virtual machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTXqLBcSfOgj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "28bd5fd2-45ad-47b2-d144-a26451457187"
      },
      "source": [
        "do_prioritization(\\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_prioritization_expr.tsv'), \\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'pancan_disease_types.gXc'), \\\n",
        "    PRIORITIZATION1_DIR_PATH, 't_test', 'average', 100, 50, None, None, None)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unexpected error during reading input file /content/gdrive/My Drive/College of Medicine Data Science Project/Genomics/example_analyses/results/prioritization1/pancan_disease_types_ETL.tsv: <class 'FileNotFoundError'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-13466fa581d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mPRIORITIZATION_OMICS_FILE_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_DATA_DIR_PATH\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0;34m'in_prioritization_expr.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprioritization1_dir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_DATA_DIR_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prioritization1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdo_prioritization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPRIORITIZATION_OMICS_FILE_PATH\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_DATA_DIR_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pancan_disease_types.gXc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0mprioritization1_dir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't_test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-1f7f13068642>\u001b[0m in \u001b[0;36mdo_prioritization\u001b[0;34m(omics_file_path, phenotype_file_path, results_dir_path, correlation_measure, missing_value_strategy, num_exported_features, num_response_correlated_features, species_id, interaction_network_edge_file_path, network_influence)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;34m'method'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'correlation'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         })\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mfeature_prioritization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrelation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprioritization_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdo_characterization\u001b[0m\u001b[0;34m(\u001b[0m    \u001b[0mgene_matrix_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_dir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecies_id\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0mgene_property_edge_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteraction_network_edge_file_path\u001b[0m\u001b[0;34m,\u001b[0m     \u001b[0mnetwork_influence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/knfeatureprioritization/feature_prioritization.py\u001b[0m in \u001b[0;36mcorrelation\u001b[0;34m(run_parameters)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"\"\" feature prioritization \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfeature_prioritization_toolbox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_correlation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mrun_correlation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbootstrap_correlation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/knfeatureprioritization/feature_prioritization_toolbox.py\u001b[0m in \u001b[0;36mrun_correlation\u001b[0;34m(run_parameters)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mrun_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"results_tmp_directory\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"results_directory\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tmp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mphenotype_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_spreadsheet_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"phenotype_name_full_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mspreadsheet_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_spreadsheet_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"spreadsheet_name_full_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mphenotype_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphenotype_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/knpackage/toolbox.py\u001b[0m in \u001b[0;36mget_spreadsheet_df\u001b[0;34m(spreadsheet_name_full_path)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mspreadsheet_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspreadsheet_name_full_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# casting index and columns to String type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/content/gdrive/My Drive/College of Medicine Data Science Project/Genomics/example_analyses/results/prioritization1/pancan_disease_types_ETL.tsv' does not exist: b'/content/gdrive/My Drive/College of Medicine Data Science Project/Genomics/example_analyses/results/prioritization1/pancan_disease_types_ETL.tsv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNkmEKAbfq7l",
        "colab_type": "text"
      },
      "source": [
        "In the second of the three prioritization cells, the phenotypes are again the PANCAN disease types, but the method incorporates the knowledge network. Again, run the cell and wait until it finishes.\n",
        "\n",
        "As with all of the analysis cells, it will store the results to your Google Drive. For that reason, you **will not** need to re-run this cell whenever your notebook connects to a new virtual machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dugvbIPxgBkq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "do_prioritization(\\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_prioritization_expr.tsv'), \\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'pancan_disease_types.gXc'), \\\n",
        "    PRIORITIZATION2_DIR_PATH, 't_test', 'average', 100, 50, '9606', \\\n",
        "    '/network/Gene/9606/hn_IntNet/9606.hn_IntNet.edge', 0.5):"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn1YlqtogXoX",
        "colab_type": "text"
      },
      "source": [
        "In the third of the three prioritization cells, the phenotypes are the COCA cluster assignments. The standard method is used.\n",
        "\n",
        "Run the cell and wait until it finishes.\n",
        "\n",
        "As with all of the analysis cells, it will store the results to your Google Drive. For that reason, you **will not** need to re-run this cell whenever your notebook connects to a new virtual machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9E9efqLgnUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "do_prioritization(\\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'in_prioritization_expr.tsv'), \\\n",
        "    os.path.join(INPUT_DATA_DIR_PATH, 'out_clustering6_assignments.tsv'), \\\n",
        "    PRIORITIZATION3_DIR_PATH, 't_test', 'average', 100, 50, None, None, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWH5pdx8lVhh",
        "colab_type": "text"
      },
      "source": [
        "## Gene-Set Characterization\n",
        "\n",
        "The final three cells compare the top genes found by the gene prioritization analyses with gene sets from the Gene Ontology database.\n",
        "\n",
        "Each cell in this sequence corresponds to one of the three gene prioritization analyses above. Run each cell and wait for it to finish.\n",
        "\n",
        "As with all of the analysis cells, these will store the results to your Google Drive. For that reason, you **will not** need to re-run these cells whenever your notebook connects to a new virtual machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqoPge_4mcHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "do_characterization(\\\n",
        "    FIXME GENE MATRIX, characterization1_dir_path, '9606', \\\n",
        "    '/network/Property/9606/gene_ontology/9606.gene_ontology.edge',\n",
        "    None, None)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}